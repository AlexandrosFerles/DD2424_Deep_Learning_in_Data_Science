{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical as make_class_categorical\n",
    "import _pickle as pickle\n",
    "from tqdm import tqdm\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2 functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(d=3072, m=50, K=10, std=0.001):\n",
    "    \"\"\"\n",
    "    Initializes the weight and bias arrays for the 2 layers of the network\n",
    "\n",
    "    :param d: Dimensionality of the input data\n",
    "    :param m: Number of nodes in the first layer\n",
    "    :param K: Number of different classes (K=10 for the CIFAR-10 dataset)\n",
    "    :param variance (optional): The variance of the normal distribution that will be used for the initialization of the weights\n",
    "\n",
    "    :return: Weights and bias arrays for the first and second layer of the neural network\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(400)\n",
    "\n",
    "    W1 = np.random.normal(0, std, size=(m, d))\n",
    "    b1 = np.zeros(shape=(m, 1))\n",
    "\n",
    "    W2 = np.random.normal(0, std, size=(K, m))\n",
    "    b2 = np.zeros(shape=(K, 1))\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBatch(filename):\n",
    "    \"\"\"\n",
    "    Loads batch based on the given filename and produces the X, Y, and y arrays\n",
    "\n",
    "    :param filename: Path of the file\n",
    "    :return: X, Y and y arrays\n",
    "    \"\"\"\n",
    "\n",
    "    # borrowed from https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "\n",
    "    dictionary = unpickle(filename)\n",
    "\n",
    "    # borrowed from https://stackoverflow.com/questions/16977385/extract-the-nth-key-in-a-python-dictionary?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n",
    "    def ix(dic, n):  # don't use dict as  a variable name\n",
    "        try:\n",
    "            return list(dic)[n]  # or sorted(dic)[n] if you want the keys to be sorted\n",
    "        except IndexError:\n",
    "            print('not enough keys')\n",
    "\n",
    "    garbage = ix(dictionary, 1)\n",
    "    y = dictionary[garbage]\n",
    "    Y = np.transpose(make_class_categorical(y, 10))\n",
    "    garbage = ix(dictionary, 2)\n",
    "    X = np.transpose(dictionary[garbage]) / 255\n",
    "\n",
    "    return X, Y, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    \"\"\"\n",
    "    Rectified Linear Unit function\n",
    "\n",
    "    :param x: Input to the function\n",
    "\n",
    "    :return: Output of ReLU(x)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, theta=1.0, axis=None):\n",
    "\n",
    "    # Softmax over numpy rows and columns, taking care for overflow cases\n",
    "    # Many thanks to https://nolanbconaway.github.io/blog/2017/softmax-numpy\n",
    "    # Usage: Softmax over rows-> axis =0, softmax over columns ->axis =1\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the softmax of each element along an axis of X.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ND-Array. Probably should be floats.\n",
    "    theta (optional): float parameter, used as a multiplier\n",
    "        prior to exponentiation. Default = 1.0\n",
    "    axis (optional): axis to compute values along. Default is the\n",
    "        first non-singleton axis.\n",
    "    Returns an array the same size as X. The result will sum to 1\n",
    "    along the specified axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # make X at least 2d\n",
    "    y = np.atleast_2d(X)\n",
    "\n",
    "    # find axis\n",
    "    if axis is None:\n",
    "        axis = next(j[0] for j in enumerate(y.shape) if j[1] > 1)\n",
    "\n",
    "    # multiply y against the theta parameter,\n",
    "    y = y * float(theta)\n",
    "\n",
    "    # subtract the max for numerical stability\n",
    "    y = y - np.expand_dims(np.max(y, axis=axis), axis)\n",
    "\n",
    "    # exponentiate y\n",
    "    y = np.exp(y)\n",
    "\n",
    "    # take the sum along the specified axis\n",
    "    ax_sum = np.expand_dims(np.sum(y, axis=axis), axis)\n",
    "\n",
    "    # finally: divide elementwise\n",
    "    p = y / ax_sum\n",
    "\n",
    "    # flatten if X was 1D\n",
    "    if len(X.shape) == 1: p = p.flatten()\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateClassifier(X, W1, b1, W2, b2):\n",
    "    \"\"\"\n",
    "    Computes the Softmax output of the 2 layer network, based on input data X and trained weight and bias arrays\n",
    "\n",
    "    :param X: Input data\n",
    "    :param W1: Weight array of the first layer\n",
    "    :param b1: Bias vector of the first layer\n",
    "    :param W2: Weight array of the second layer\n",
    "    :param b2: Bias vector of the second layer\n",
    "\n",
    "    :return: Softmax output of the trained network\n",
    "    \"\"\"\n",
    "    s1 = np.dot(W1, X) + b1\n",
    "    h = ReLU(s1)\n",
    "    s = np.dot(W2, h) + b2\n",
    "    p = softmax(s, axis=0)\n",
    "\n",
    "    return p, h, s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictClasses(p):\n",
    "    \"\"\"\n",
    "    Predicts classes based on the softmax output of the network\n",
    "\n",
    "    :param p: Softmax output of the network\n",
    "    :return: Predicted classes\n",
    "    \"\"\"\n",
    "\n",
    "    return np.argmax(p, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAccuracy(X, y, W1, b1, W2, b2):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the feed-forward 2-layer network\n",
    "\n",
    "    :param X: Input data\n",
    "    :param y: Labels of the ground truth\n",
    "    :param W1: Weight matrix of the first layer\n",
    "    :param b1: Bias vector of the first layer\n",
    "    :param W2: Weight matrix of the second layer\n",
    "    :param b2: Bias vector of the second layer\n",
    "\n",
    "    :return: Accuracy metric of the neural network.\n",
    "    \"\"\"\n",
    "    p, _, _ = EvaluateClassifier(X=X, W1=W1, b1=b1, W2=W2, b2=b2)\n",
    "    predictions = predictClasses(p)\n",
    "\n",
    "    accuracy = round(np.sum(np.where(predictions - y == 0, 1, 0)) * 100 / len(y), 2)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeCost(X, Y, W1, W2, b1, b2, regularization_term= 0):\n",
    "    \"\"\"\n",
    "    Computes the cross-entropy loss on a batch of data.\n",
    "\n",
    "    :param X: Input data\n",
    "    :param y: Labels of the ground truth\n",
    "    :param W1: Weight matrix of the first layer\n",
    "    :param b1: Bias vector of the first layer\n",
    "    :param W2: Weight matrix of the second layer\n",
    "    :param b2: Bias vector of the second layer\n",
    "    :param regularization_term: Amount of regularization applied.\n",
    "\n",
    "    :return: Cross-entropy loss.\n",
    "    \"\"\"\n",
    "    p, _, _ = EvaluateClassifier(X=X, W1=W1, b1=b1, W2=W2, b2=b2)\n",
    "\n",
    "    cross_entropy_loss = -np.log(np.diag(np.dot(Y.T, p))).sum() / float(X.shape[1])\n",
    "\n",
    "    weight_sum = np.power(W1, 2).sum() + np.power(W2, 2).sum()\n",
    "\n",
    "    return cross_entropy_loss + regularization_term * weight_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeGradsNum(X, Y, W1, b1, W2, b2, regularization_term, h=1e-5):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes gradient descent updates on a batch of data with numerical computations.\n",
    "    Contributed by Josephine Sullivan for educational purposes for the DD2424 Deep Learning in Data Science course.\n",
    "\n",
    "    :param X: Input data\n",
    "    :param Y: One-hot representation of the true labels of input data X\n",
    "    :param W1: Weight matrix of the first layer\n",
    "    :param b1: Bias vector of the first layer\n",
    "    :param W2: Weight matrix of the second layer\n",
    "    :param b2: Bias vector of the second layer\n",
    "    :param regularization_term: Contribution of the regularization in the weight updates\n",
    "\n",
    "    :return: Weight and bias updates of the first and second layer of our network computed with numerical computations\n",
    "    \"\"\"\n",
    "\n",
    "    grad_W1= np.zeros((W1.shape[0], W1.shape[1]))\n",
    "    grad_b1= np.zeros((W1.shape[0], 1))\n",
    "    grad_W2= np.zeros((W2.shape[0], W2.shape[1]))\n",
    "    grad_b2= np.zeros((W2.shape[0], 1))\n",
    "    \n",
    "    c = ComputeCost(X=X, Y=Y, W1=W1, b1=b1, W2=W2, b2=b2, regularization_term=regularization_term)\n",
    "    \n",
    "    for i in range(b1.shape[0]):\n",
    "        b1_try = np.copy(b1)\n",
    "        b1_try[i, 0] += h\n",
    "        c2 = ComputeCost(X=X, Y=Y, W1=W1, b1=b1_try, W2=W2, b2=b2, regularization_term=regularization_term)\n",
    "        grad_b1[i,0] = (c2-c) / h\n",
    "\n",
    "    for i in range(b2.shape[0]):\n",
    "        b2_try= np.copy(b2)\n",
    "        b2_try[i, 0] += h\n",
    "        c2 = ComputeCost(X=X, Y=Y, W1=W1, b1=b1, W2=W2, b2=b2_try, regularization_term=regularization_term)\n",
    "        grad_b2[i,0] = (c2-c) / h\n",
    "        \n",
    "    for i in range(W1.shape[0]):\n",
    "        for j in range(W1.shape[1]):\n",
    "            \n",
    "            W1_try= np.copy(W1)\n",
    "            W1_try[i,j] += h\n",
    "            c2= ComputeCost(X=X, Y=Y, W1=W1_try, b1=b1, W2=W2, regularization_term=regularization_term)\n",
    "            \n",
    "            grad_W1[i,j] = (c2-c) / h\n",
    "\n",
    "    for i in range(W2.shape[0]):\n",
    "        for j in range(W2.shape[1]):\n",
    "            W2_try = np.copy(W2)\n",
    "            W2_try[i, j] += h\n",
    "            c2 = ComputeCost(X=X, Y=Y, W1=W1, b1=b1, W2=W2_try, regularization_term=regularization_term)\n",
    "\n",
    "            grad_W2[i, j] = (c2 - c) / h\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeGradsNumSlow(X, Y, W1, b1, W2, b2, regularization_term, h=1e-5):\n",
    "    \"\"\"\n",
    "    Computes gradient descent updates on a batch of data with numerical computations of great precision, thus slower computations.\n",
    "    Contributed by Josephine Sullivan for educational purposes for the DD2424 Deep Learning in Data Science course.\n",
    "\n",
    "    :param X: Input data\n",
    "    :param Y: One-hot representation of the true labels of input data X\n",
    "    :param W1: Weight matrix of the first layer\n",
    "    :param b1: Bias vector of the first layer\n",
    "    :param W2: Weight matrix of the second layer\n",
    "    :param b2: Bias vector of the second layer\n",
    "    :param regularization_term: Contribution of the regularization in the weight updates\n",
    "\n",
    "    :return: Weight and bias updates of the first and second layer of our network computed with numerical computations with high precision.\n",
    "    \"\"\"\n",
    "\n",
    "    grad_W1= np.zeros((W1.shape[0], W1.shape[1]))\n",
    "    grad_b1= np.zeros((b1.shape[0], 1))\n",
    "    grad_W2= np.zeros((W2.shape[0], W2.shape[1]))\n",
    "    grad_b2= np.zeros((b2.shape[0], 1))\n",
    "    \n",
    "    for i in tqdm(range(b1.shape[0])):\n",
    "\n",
    "        b1_try = np.copy(b1)\n",
    "        b1_try[i,0] -= h\n",
    "        c1 = ComputeCost(X=X, Y=Y, W1=W1, b1=b1_try, W2=W2, b2=b2, regularization_term=regularization_term)\n",
    "        b1_try = np.copy(b1)\n",
    "        b1_try[i,0] += h\n",
    "        c2 = ComputeCost(X=X, Y=Y, W1=W1, b1=b1_try, W2=W2, b2=b2, regularization_term=regularization_term)\n",
    "        grad_b1[i,0] = (c2-c1)/(2*h)\n",
    "\n",
    "    for i in tqdm(range(b2.shape[0])):\n",
    "        b2_try = np.copy(b2)\n",
    "        b2_try[i, 0] -= h\n",
    "        c1 = ComputeCost(X=X, Y=Y, W1=W1, b1=b1, W2=W2, b2=b2_try, regularization_term=regularization_term)\n",
    "\n",
    "        b2_try = np.copy(b2)\n",
    "        b2_try[i, 0] += h\n",
    "        c2 = ComputeCost(X=X, Y=Y, W1=W1, b1=b1, W2=W2, b2=b2_try, regularization_term=regularization_term)\n",
    "        grad_b2[i, 0] = (c2 - c1) / (2 * h)\n",
    "\n",
    "    for i in tqdm(range(W1.shape[0])):\n",
    "        for j in tqdm(range(W1.shape[1])):\n",
    "\n",
    "            W1_try = np.copy(W1)\n",
    "            W1_try[i, j] -= h\n",
    "            c1 = ComputeCost(X=X, Y=Y, W1=W1_try, b1=b1, W2=W2, b2=b2, regularization_term=regularization_term)\n",
    "\n",
    "            W1_try = np.copy(W1)\n",
    "            W1_try[i, j] += h\n",
    "            c2 = ComputeCost(X=X, Y=Y, W1=W1_try, b1=b1, W2=W2, b2=b2, regularization_term=regularization_term)\n",
    "\n",
    "            grad_W1[i, j] = (c2 - c1) / (2 * h)\n",
    "\n",
    "    for i in tqdm(range(W2.shape[0])):\n",
    "        for j in tqdm(range(W2.shape[1])):\n",
    "\n",
    "            W2_try = np.copy(W2)\n",
    "            W2_try[i, j] -= h\n",
    "            c1 = ComputeCost(X=X, Y=Y, W1=W1, b1=b1, W2=W2_try, b2=b2, regularization_term=regularization_term)\n",
    "\n",
    "            W2_try = np.copy(W2)\n",
    "            W2_try[i, j] += h\n",
    "            c2 = ComputeCost(X=X, Y=Y, W1=W1, b1=b1, W2=W2_try, b2=b2, regularization_term=regularization_term)\n",
    "\n",
    "            grad_W2[i, j] = (c2 - c1) / (2 * h)\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeGradients(X, Y, W1, b1, W2, b2, p, h, s1, regularization_term= 0):\n",
    "    \"\"\"\n",
    "    Computes gradient descent updates on a batch of data\n",
    "\n",
    "    :param X: Input data\n",
    "    :param Y: One-hot representation of the true labels of input data X\n",
    "    :param W1: Weight matrix of the first layer\n",
    "    :param b1: Bias vector of the first layer\n",
    "    :param W2: Weight matrix of the second layer\n",
    "    :param b2: Bias vector of the second layer\n",
    "    :param p: Softmax probabilities (predictions) of the network over classes.\n",
    "    :param h: ReLU activations of the network.\n",
    "    :param s1: True outout of the first layer of the network.\n",
    "    :param regularization_term: Contribution of the regularization in the weight updates\n",
    "\n",
    "    :return: Weight and bias updates of the first and second layer of our network\n",
    "    \"\"\"\n",
    "\n",
    "    # Back-propagate second layer at first\n",
    "\n",
    "    g = p - Y\n",
    "    grad_b2 = g.sum(axis=1).reshape(b2.shape)\n",
    "    grad_W2 = np.dot(g, h.T)\n",
    "\n",
    "    # Back-propagate the gradient vector g to the first layer\n",
    "    g = np.dot(g.T, W2)\n",
    "    ind = 1 * (s1 > 0)\n",
    "    g = g.T * ind\n",
    "\n",
    "    grad_b1 = np.sum(g, axis=1).reshape(b1.shape)\n",
    "    grad_W1 = np.dot(g, X.T)\n",
    "\n",
    "    grad_W1 /= X.shape[1]\n",
    "    grad_b1 /= X.shape[1]\n",
    "    grad_W2 /= X.shape[1]\n",
    "    grad_b2 /= X.shape[1]\n",
    "\n",
    "    # Add regularizers\n",
    "    grad_W1 = grad_W1 + 2 * regularization_term * W1\n",
    "    grad_W2 = grad_W2 +2 * regularization_term * W2\n",
    "\n",
    "    return grad_W1, grad_b1, grad_W2, grad_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(gradW1, gradb1, gradW2, gradb2, gradW1_num, gradb1_num, gradW2_num, gradb2_num, threshold = 1e-4):\n",
    "\n",
    "    \"\"\"\n",
    "    Compares the gradients of both the analytical and numerical method and prints out a message of result \n",
    "    or failure, depending on how close these gradients are between each other.\n",
    "    \n",
    "    :param gradW1: Gradient of W1, analytically computed\n",
    "    :param gradb1: Gradient of b1, analytically computed\n",
    "    :param gradW2: Gradient of W2, analytically computed\n",
    "    :param gradb2: Gradient of b2, analytically computed\n",
    "    :param gradW1_num: Gradient of W1, numerically computed\n",
    "    :param gradb1_num: Gradient of b1, numerically computed\n",
    "    :param gradW2_num: Gradient of W2, numerically computed\n",
    "    :param gradb2_num: Gradient of b2, numerically computed\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    W1_abs = np.abs(gradW1 - gradW1_num)\n",
    "    b1_abs = np.abs(gradb1 - gradb1_num)\n",
    "    \n",
    "    W2_abs = np.abs(gradW2 - gradW2_num)\n",
    "    b2_abs = np.abs(gradb2 - gradb2_num)\n",
    "    \n",
    "    W1_nominator = np.average(W1_abs)\n",
    "    b1_nominator = np.average(b1_abs)\n",
    "    \n",
    "    W2_nominator = np.average(W2_abs)\n",
    "    b2_nominator = np.average(b2_abs)\n",
    "\n",
    "\n",
    "    gradW1_abs = np.absolute(gradW1)\n",
    "    gradW1_num_abs = np.absolute(gradW1_num)\n",
    "    \n",
    "    gradW2_abs = np.absolute(gradW2)\n",
    "    gradW2_num_abs = np.absolute(gradW2_num)\n",
    "\n",
    "    gradb1_abs = np.absolute(gradb1)\n",
    "    gradb1_num_abs = np.absolute(gradb1)\n",
    "    \n",
    "    gradb2_abs = np.absolute(gradb2)\n",
    "    gradb2_num_abs = np.absolute(gradb2)\n",
    "\n",
    "    sum_W1 = gradW1_abs + gradW1_num_abs\n",
    "    sum_W2 = gradW2_abs + gradW2_num_abs\n",
    "    sum_b1 = gradb1_abs + gradb1_num_abs\n",
    "    sum_b2 = gradb2_abs + gradb2_num_abs\n",
    "\n",
    "    check_W1 = W1_nominator / np.amax(sum_W1)\n",
    "    check_b1 = b1_nominator / np.amax(sum_b1)\n",
    "\n",
    "    check_W2 = W2_nominator / np.amax(sum_W2)\n",
    "    check_b2 = b2_nominator / np.amax(sum_b2)\n",
    "\n",
    "\n",
    "    if check_W1 < threshold and check_b1 < threshold and check_W2 < threshold and check_b2 < threshold:\n",
    "        print( \"Success!!\")\n",
    "        print(\"Average error on weights of first layer= \", check_W1)\n",
    "        print(\"Average error on bias of first layer=\", check_b1)\n",
    "        print(\"Average error on weights of second layer= \", check_W2)\n",
    "        print(\"Average error on bias of second layer= \", check_b2)\n",
    "    else:\n",
    "        print(\"Failure\")\n",
    "        print(\"Average error on weights of first layer= \", check_W1)\n",
    "        print(\"Average error on bias of first layer=\", check_b1)\n",
    "        print(\"Average error on weights of second layer= \", check_W2)\n",
    "        print(\"Average error on bias of second layer= \", check_b2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_momentum(hyperparameter):\n",
    "    \"\"\"\n",
    "    Initializes the corresponding momentum of a hyperparameter matrix or vector\n",
    "\n",
    "    :param hyperparameter: The hyperparameter\n",
    "    :return: The corresponding momentum\n",
    "    \"\"\"\n",
    "\n",
    "    return np.zeros(hyperparameter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_momentum(v_t_prev, hyperpatameter, gradient, eta, momentum_term=0.99):\n",
    "    \"\"\"\n",
    "    Add momentum to the update of the hyperparameter at each update step, in order to speed up training\n",
    "\n",
    "    :param v_t_prev: The momentum update of the previous time step\n",
    "    :param hyperpatameter: The corresponding hyperparameters\n",
    "    :param gradient: The value of the gradient update as computed in each time step\n",
    "    :param eta: The learning rate of the training process\n",
    "    :param r (optional): The momentum factor, typically 0.9 or 0.99\n",
    "\n",
    "    :return: The updated hyperparameter based on the momentum update, and the  momentum update itself\n",
    "    \"\"\"\n",
    "\n",
    "    v_t = momentum_term * v_t_prev + eta * gradient\n",
    "\n",
    "    return hyperpatameter - v_t, v_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniBatchGD(X, Y, X_validation, Y_validation, GDparams, W1, b1, W2, b2, regularization_term = 0):\n",
    "    \"\"\"\n",
    "    Performs mini batch-gradient descent computations.\n",
    "\n",
    "    :param X: Input batch of data\n",
    "    :param Y: One-hot representation of the true labels of the data.\n",
    "    :param X_validation: Input batch of validation data.\n",
    "    :param Y_validation: One-hot representation of the true labels of the validation data.\n",
    "    :param GDparams: Gradient descent parameters (number of mini batches to construct, learning rate, epochs)\n",
    "    :param W1: Weight matrix of the first layer of the network.\n",
    "    :param b1: Bias vector of the first layer of the network.\n",
    "    :param W2: Weight matrix of the second layer of the network.\n",
    "    :param b2: Bias vector of the second layer of the network.\n",
    "    :param regularization_term: Amount of regularization applied.\n",
    "\n",
    "    :return: The weight and bias matrices learnt (trained) from the training process, loss in training and validation set.\n",
    "    \"\"\"\n",
    "    number_of_mini_batches = GDparams[0]\n",
    "    eta = GDparams[1]\n",
    "    epoches = GDparams[2]\n",
    "\n",
    "    cost = []\n",
    "    val_cost = []\n",
    "\n",
    "    for _ in tqdm(range(epoches)):\n",
    "\n",
    "        for batch in range(1, int(X.shape[1] / number_of_mini_batches)):\n",
    "            start = (batch - 1) * number_of_mini_batches + 1\n",
    "            end = batch * number_of_mini_batches + 1\n",
    "\n",
    "            p, h, s1 = EvaluateClassifier(X[:,start:end], W1, b1, W2, b2)\n",
    "\n",
    "            grad_W1, grad_b1, grad_W2, grad_b2 = ComputeGradients(X[:,start:end], Y[:,start:end], W1, b1, W2, b2, p, h ,s1, regularization_term)\n",
    "\n",
    "            W1 -= eta * grad_W1\n",
    "            b1 -= eta * grad_b1\n",
    "            W2 -= eta * grad_W2\n",
    "            b2 -= eta * grad_b2\n",
    "\n",
    "        epoch_cost = ComputeCost(X, Y, W1, W2, b1, b2, 0)\n",
    "        val_epoch_cost = ComputeCost(X_validation, Y_validation, W1, W2, b1, b2)\n",
    "\n",
    "        cost.append(epoch_cost)\n",
    "        val_cost.append(val_epoch_cost)\n",
    "\n",
    "    return W1, b1, W2, b2, cost, val_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniBatchGDwithMomentum(X, Y, X_validation, Y_validation, y_validation, GDparams, W1, b1, W2, b2, regularization_term = 0, momentum_term=0.9):\n",
    "    \"\"\"\n",
    "    Performs mini batch-gradient descent computations.\n",
    "\n",
    "    :param X: Input batch of data\n",
    "    :param Y: One-hot representation of the true labels of the data.\n",
    "    :param X_validation: Input batch of validation data.\n",
    "    :param Y_validation: One-hot representation of the true labels of the validation data.\n",
    "    :param GDparams: Gradient descent parameters (number of mini batches to construct, learning rate, epochs)\n",
    "    :param W1: Weight matrix of the first layer of the network.\n",
    "    :param b1: Bias vector of the first layer of the network.\n",
    "    :param W2: Weight matrix of the second layer of the network.\n",
    "    :param b2: Bias vector of the second layer of the network.\n",
    "    :param regularization_term: Amount of regularization applied.\n",
    "\n",
    "    :return: The weight and bias matrices learnt (trained) from the training process, loss in training and validation set.\n",
    "    \"\"\"\n",
    "    number_of_mini_batches = GDparams[0]\n",
    "    eta = GDparams[1]\n",
    "    epoches = GDparams[2]\n",
    "\n",
    "    cost = []\n",
    "    val_cost = []\n",
    "\n",
    "    v_W1 = initialize_momentum(W1)\n",
    "    v_b1 = initialize_momentum(b1)\n",
    "    v_W2 = initialize_momentum(W2)\n",
    "    v_b2 = initialize_momentum(b2)\n",
    "\n",
    "    # print('Training set loss before start of training process: '+str(ComputeCost(X, Y, W1, W2, b1, b2, regularization_term)))\n",
    "\n",
    "    original_training_cost = ComputeCost(X, Y, W1, W2, b1, b2, regularization_term)\n",
    "    \n",
    "    best_W1 = np.copy(W1)\n",
    "    best_b1 = np.copy(b1)\n",
    "    best_W2 = np.copy(W2)\n",
    "    best_b2 = np.copy(b2)\n",
    "    \n",
    "    best_validation_set_accuracy = 0\n",
    "\n",
    "    for epoch in tqdm(range(epoches)):\n",
    "    # for epoch in range(epoches):\n",
    "\n",
    "        for batch in range(1, int(X.shape[1] / number_of_mini_batches)):\n",
    "            start = (batch - 1) * number_of_mini_batches + 1\n",
    "            end = batch * number_of_mini_batches + 1\n",
    "\n",
    "            p, h, s1 = EvaluateClassifier(X[:,start:end], W1, b1, W2, b2)\n",
    "\n",
    "            grad_W1, grad_b1, grad_W2, grad_b2 = ComputeGradients(X[:,start:end], Y[:,start:end], W1, b1, W2, b2, p, h ,s1, regularization_term)\n",
    "\n",
    "            W1, v_W1 = add_momentum(v_W1, W1, grad_W1, eta, momentum_term)\n",
    "            b1, v_b1 = add_momentum(v_b1, b1, grad_b1, eta, momentum_term)\n",
    "            W2, v_W2 = add_momentum(v_W2, W2, grad_W2, eta, momentum_term)\n",
    "            b2, v_b2 = add_momentum(v_b2, b2, grad_b2, eta, momentum_term)\n",
    "            \n",
    "        validation_set_accuracy = ComputeAccuracy(X_validation, y_validation, W1, b1, W2, b2)\n",
    "        \n",
    "        if validation_set_accuracy > best_validation_set_accuracy:\n",
    "            \n",
    "            best_W1 = np.copy(W1)\n",
    "            best_b1 = np.copy(b1)\n",
    "            best_W2 = np.copy(W2)\n",
    "            best_b2 = np.copy(b2)\n",
    "            \n",
    "            best_validation_set_accuracy = validation_set_accuracy\n",
    "\n",
    "        epoch_cost = ComputeCost(X, Y, W1, W2, b1, b2)\n",
    "        # print('Training set loss after epoch number '+str(epoch)+' is: '+str(epoch_cost))\n",
    "        if epoch_cost > 3 * original_training_cost:\n",
    "            break\n",
    "        val_epoch_cost = ComputeCost(X_validation, Y_validation, W1, W2, b1, b2)\n",
    "\n",
    "        cost.append(epoch_cost)\n",
    "        val_cost.append(val_epoch_cost)\n",
    "\n",
    "        # Decay the learning rate\n",
    "        eta *= 0.95\n",
    "\n",
    "    # return W1, b1, W2, b2, cost, val_cost\n",
    "    return best_W1, best_b1, best_W2, best_b2, cost, val_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_single_cost(loss, display= False, title = None, save_name= None, save_path='../figures/'):\n",
    "    \"\"\"\n",
    "        Visualization and saving the loss of the network.\n",
    "\n",
    "        :param loss: Loss of the network.\n",
    "        :param display: (Optional) Boolean, set to True for displaying the loss evolution plot.\n",
    "        :param title: (Optional) Title of the plot.\n",
    "        :param save_name: (Optional) name of the file to save the plot.\n",
    "        :param save_path: (Optional) Path of the folder to save the plot in your local computer.\n",
    "\n",
    "        :return: None\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.plot(loss)\n",
    "\n",
    "    if save_name is not None:\n",
    "        if save_path[-1] != '/':\n",
    "            save_path += '/'\n",
    "        plt.savefig(save_path + save_name+'.png')\n",
    "\n",
    "    if display:\n",
    "        plt.show()\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_costs(loss, val_loss, display= False, title = None, save_name= None, save_path='../figures/'):\n",
    "    \"\"\"\n",
    "    Visualization and saving the losses of the network.\n",
    "\n",
    "    :param loss: Loss of the network.\n",
    "    :param val_loss: Loss of the network in the validation set.\n",
    "    :param display: (Optional) Boolean, set to True for displaying the loss evolution plot.\n",
    "    :param title: (Optional) Title of the plot.\n",
    "    :param save_name: (Optional) name of the file to save the plot.\n",
    "    :param save_path: (Optional) Path of the folder to save the plot in your local computer.\n",
    "\n",
    "    :return: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.plot(loss, 'g', label='Training set ')\n",
    "    plt.plot(val_loss, 'r', label='Validation set')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    if save_name is not None:\n",
    "        if save_path[-1] !='/':\n",
    "            save_path+='/'\n",
    "        plt.savefig(save_path + save_name)\n",
    "\n",
    "    if display:\n",
    "        plt.show()\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSIGNMENT 2 EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Exercise 1: Read in the data & initialize the parameters ofthe network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_1():\n",
    "    \"\"\"\n",
    "    DD2424 Assignemnt 2, Exercise 1: Read the data & initialize the parameters of the network\n",
    "\n",
    "    :return: Data of the tarining and testing process and initialized parameters for the weights and bias of the network\n",
    "    \"\"\"\n",
    "    X_training_1, Y_training_1, y_training_1 = LoadBatch('../../cifar-10-batches-py/data_batch_1')\n",
    "    X_training_2, Y_training_2, y_training_2 = LoadBatch('../../cifar-10-batches-py/data_batch_2')\n",
    "    X_test, _, y_test = LoadBatch('../../cifar-10-batches-py/test_batch')\n",
    "\n",
    "    mean = np.mean(X_training_1)\n",
    "    X_training_1 -= mean\n",
    "    X_training_2 -= mean\n",
    "    X_test -= mean\n",
    "\n",
    "    training_data = [X_training_1, Y_training_1, y_training_1]\n",
    "    validation_data = [X_training_2, Y_training_2, y_training_2]\n",
    "    test_data = [X_test, y_test]\n",
    "\n",
    "    W1, b1, W2, b2 = initialize_weights(d=X_training_1.shape[0], m=50, K=Y_training_1.shape[0])\n",
    "\n",
    "    return training_data, validation_data, test_data, W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data, W1, b1, W2, b2 = exercise_1()\n",
    "X_training, Y_training, y_training = training_data\n",
    "X_validation, Y_validation, y_validation = validation_data\n",
    "X_test, y_test = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Compute the gradients for the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, h, s1 = EvaluateClassifier(X_training_1[:,0:2], W1, b1, W2, b2)\n",
    "grad_W1, grad_b1, grad_W2, grad_b2 = ComputeGradients(X_training[:,0:2], Y_training[:,0:2], W1, b1, W2, b2, p, h, s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test no.1: Compare with numerically computed gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_W1_num = np.load('grad_W1_num.npy')\n",
    "grad_b1_num = np.load('grad_b1_num.npy')\n",
    "grad_W2_num = np.load('grad_W2_num.npy')\n",
    "grad_b2_num = np.load('grad_b2_num.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!!\n",
      "Average error on weights of first layer=  7.52283628908819e-09\n",
      "Average error on bias of first layer= 4.602426280088195e-09\n",
      "Average error on weights of second layer=  3.0747216543846533e-10\n",
      "Average error on bias of second layer=  1.193638211533644e-11\n"
     ]
    }
   ],
   "source": [
    "check_similarity(grad_W1, grad_b1, grad_W2, grad_b2, grad_W1_num, grad_b1_num, grad_W2_num, grad_b2_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test no.2: Overfit on a small subset of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:09<00:00, 21.68it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W1, b1, W2, b2 = initialize_weights(d=X_training_1.shape[0], m=50, K=Y_training_1.shape[0])\n",
    "GD_params = [100, 0.05, 200]\n",
    "\n",
    "W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGD(   X_training[:, :1000],\n",
    "                                                                        Y_training[:, :1000],\n",
    "                                                                        X_validation[:, :1000],\n",
    "                                                                        Y_validation[:, :1000],\n",
    "                                                                        y_validation,\n",
    "                                                                        GD_params,\n",
    "                                                                        W1, b1, W2, b2)\n",
    "\n",
    "visualize_costs(training_set_loss, validation_set_loss, display=True, title='Cross Entropy Loss Evolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe overfitting in the training data, as the loss on the training set gets pretty small values, while the loss on the validation set starts increasing after a few number of epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Add momentum to your update step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:20<00:00,  9.59it/s]\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(   X_training[:, :2000],\n",
    "                                                                                    Y_training[:, :2000],\n",
    "                                                                                    X_validation[:, :2000],\n",
    "                                                                                    Y_validation[:, :2000],\n",
    "                                                                                    y_validation,\n",
    "                                                                                    GD_params,\n",
    "                                                                                    W1, b1, W2, b2,\n",
    "                                                                                    regularization_term=0,\n",
    "                                                                                    momentum_term=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_costs(training_set_loss, validation_set_loss, display=True, title='Cross Entropy Loss Evolution with momentum value: 0.99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/200 [00:00<00:25,  7.76it/s]\u001b[A\n",
      "  1%|          | 2/200 [00:00<00:25,  7.81it/s]\u001b[A\n",
      "  2%|▏         | 3/200 [00:00<00:25,  7.86it/s]\u001b[A\n",
      "  2%|▏         | 4/200 [00:00<00:24,  7.95it/s]\u001b[A\n",
      "  2%|▎         | 5/200 [00:00<00:24,  8.01it/s]\u001b[A\n",
      "  3%|▎         | 6/200 [00:00<00:24,  8.06it/s]\u001b[A\n",
      "  4%|▎         | 7/200 [00:00<00:23,  8.06it/s]\u001b[A\n",
      "  4%|▍         | 8/200 [00:00<00:23,  8.08it/s]\u001b[A\n",
      "  4%|▍         | 9/200 [00:01<00:23,  8.07it/s]\u001b[A\n",
      "  5%|▌         | 10/200 [00:01<00:23,  8.07it/s]\u001b[A\n",
      "  6%|▌         | 11/200 [00:01<00:23,  8.06it/s]\u001b[A\n",
      "  6%|▌         | 12/200 [00:01<00:23,  7.99it/s]\u001b[A\n",
      "  6%|▋         | 13/200 [00:01<00:23,  7.80it/s]\u001b[A\n",
      "  7%|▋         | 14/200 [00:01<00:24,  7.63it/s]\u001b[A\n",
      "  8%|▊         | 15/200 [00:02<00:24,  7.49it/s]\u001b[A\n",
      "  8%|▊         | 16/200 [00:02<00:24,  7.39it/s]\u001b[A\n",
      "  8%|▊         | 17/200 [00:02<00:25,  7.23it/s]\u001b[A\n",
      "  9%|▉         | 18/200 [00:02<00:25,  7.22it/s]\u001b[A\n",
      " 10%|▉         | 19/200 [00:02<00:25,  7.20it/s]\u001b[A\n",
      " 10%|█         | 20/200 [00:02<00:25,  7.13it/s]\u001b[A\n",
      " 10%|█         | 21/200 [00:02<00:25,  7.11it/s]\u001b[A\n",
      " 11%|█         | 22/200 [00:03<00:25,  7.04it/s]\u001b[A\n",
      " 12%|█▏        | 23/200 [00:03<00:25,  6.99it/s]\u001b[A\n",
      " 12%|█▏        | 24/200 [00:03<00:25,  6.95it/s]\u001b[A\n",
      " 12%|█▎        | 25/200 [00:03<00:25,  6.97it/s]\u001b[A\n",
      " 13%|█▎        | 26/200 [00:03<00:24,  7.01it/s]\u001b[A\n",
      " 14%|█▎        | 27/200 [00:03<00:24,  7.03it/s]\u001b[A\n",
      " 14%|█▍        | 28/200 [00:03<00:24,  7.05it/s]\u001b[A\n",
      " 14%|█▍        | 29/200 [00:04<00:24,  7.08it/s]\u001b[A\n",
      " 15%|█▌        | 30/200 [00:04<00:23,  7.11it/s]\u001b[A\n",
      " 16%|█▌        | 31/200 [00:04<00:23,  7.12it/s]\u001b[A\n",
      " 16%|█▌        | 32/200 [00:04<00:23,  7.09it/s]\u001b[A\n",
      " 16%|█▋        | 33/200 [00:04<00:23,  7.05it/s]\u001b[A\n",
      " 17%|█▋        | 34/200 [00:04<00:23,  7.08it/s]\u001b[A\n",
      " 18%|█▊        | 35/200 [00:04<00:23,  7.04it/s]\u001b[A\n",
      " 18%|█▊        | 36/200 [00:05<00:23,  7.06it/s]\u001b[A\n",
      " 18%|█▊        | 37/200 [00:05<00:23,  7.08it/s]\u001b[A\n",
      " 19%|█▉        | 38/200 [00:05<00:22,  7.10it/s]\u001b[A\n",
      " 20%|█▉        | 39/200 [00:05<00:22,  7.11it/s]\u001b[A\n",
      " 20%|██        | 40/200 [00:05<00:22,  7.07it/s]\u001b[A\n",
      " 20%|██        | 41/200 [00:05<00:22,  7.05it/s]\u001b[A\n",
      " 21%|██        | 42/200 [00:05<00:22,  7.02it/s]\u001b[A\n",
      " 22%|██▏       | 43/200 [00:06<00:22,  7.03it/s]\u001b[A\n",
      " 22%|██▏       | 44/200 [00:06<00:22,  7.05it/s]\u001b[A\n",
      " 22%|██▎       | 45/200 [00:06<00:21,  7.05it/s]\u001b[A\n",
      " 23%|██▎       | 46/200 [00:06<00:21,  7.03it/s]\u001b[A\n",
      " 24%|██▎       | 47/200 [00:06<00:21,  7.04it/s]\u001b[A\n",
      " 24%|██▍       | 48/200 [00:06<00:21,  7.05it/s]\u001b[A\n",
      " 24%|██▍       | 49/200 [00:06<00:21,  7.06it/s]\u001b[A\n",
      " 25%|██▌       | 50/200 [00:07<00:21,  7.04it/s]\u001b[A\n",
      " 26%|██▌       | 51/200 [00:07<00:21,  7.04it/s]\u001b[A\n",
      " 26%|██▌       | 52/200 [00:07<00:21,  7.04it/s]\u001b[A\n",
      " 26%|██▋       | 53/200 [00:07<00:20,  7.03it/s]\u001b[A\n",
      " 27%|██▋       | 54/200 [00:07<00:20,  7.02it/s]\u001b[A\n",
      " 28%|██▊       | 55/200 [00:07<00:20,  7.01it/s]\u001b[A\n",
      " 28%|██▊       | 56/200 [00:07<00:20,  7.02it/s]\u001b[A\n",
      " 28%|██▊       | 57/200 [00:08<00:20,  7.01it/s]\u001b[A\n",
      " 29%|██▉       | 58/200 [00:08<00:20,  7.01it/s]\u001b[A\n",
      " 30%|██▉       | 59/200 [00:08<00:20,  7.01it/s]\u001b[A\n",
      " 30%|███       | 60/200 [00:08<00:20,  6.99it/s]\u001b[A\n",
      " 30%|███       | 61/200 [00:08<00:19,  7.00it/s]\u001b[A\n",
      " 31%|███       | 62/200 [00:08<00:19,  7.00it/s]\u001b[A\n",
      " 32%|███▏      | 63/200 [00:09<00:19,  6.98it/s]\u001b[A\n",
      " 32%|███▏      | 64/200 [00:09<00:19,  6.98it/s]\u001b[A\n",
      " 32%|███▎      | 65/200 [00:09<00:19,  6.97it/s]\u001b[A\n",
      " 33%|███▎      | 66/200 [00:09<00:19,  6.95it/s]\u001b[A\n",
      " 34%|███▎      | 67/200 [00:09<00:19,  6.94it/s]\u001b[A\n",
      " 34%|███▍      | 68/200 [00:09<00:19,  6.93it/s]\u001b[A\n",
      " 34%|███▍      | 69/200 [00:09<00:18,  6.93it/s]\u001b[A\n",
      " 35%|███▌      | 70/200 [00:10<00:18,  6.94it/s]\u001b[A\n",
      " 36%|███▌      | 71/200 [00:10<00:18,  6.95it/s]\u001b[A\n",
      " 36%|███▌      | 72/200 [00:10<00:18,  6.93it/s]\u001b[A\n",
      " 36%|███▋      | 73/200 [00:10<00:18,  6.93it/s]\u001b[A\n",
      " 37%|███▋      | 74/200 [00:10<00:18,  6.91it/s]\u001b[A\n",
      " 38%|███▊      | 75/200 [00:10<00:18,  6.90it/s]\u001b[A\n",
      " 38%|███▊      | 76/200 [00:11<00:17,  6.91it/s]\u001b[A\n",
      " 38%|███▊      | 77/200 [00:11<00:17,  6.92it/s]\u001b[A\n",
      " 39%|███▉      | 78/200 [00:11<00:17,  6.93it/s]\u001b[A\n",
      " 40%|███▉      | 79/200 [00:11<00:17,  6.95it/s]\u001b[A\n",
      " 40%|████      | 80/200 [00:11<00:17,  6.96it/s]\u001b[A\n",
      " 40%|████      | 81/200 [00:11<00:17,  6.97it/s]\u001b[A\n",
      " 41%|████      | 82/200 [00:11<00:16,  6.98it/s]\u001b[A\n",
      " 42%|████▏     | 83/200 [00:11<00:16,  6.99it/s]\u001b[A\n",
      " 42%|████▏     | 84/200 [00:12<00:16,  7.00it/s]\u001b[A\n",
      " 42%|████▎     | 85/200 [00:12<00:16,  7.01it/s]\u001b[A\n",
      " 43%|████▎     | 86/200 [00:12<00:16,  7.01it/s]\u001b[A\n",
      " 44%|████▎     | 87/200 [00:12<00:16,  7.02it/s]\u001b[A\n",
      " 44%|████▍     | 88/200 [00:12<00:15,  7.03it/s]\u001b[A\n",
      " 44%|████▍     | 89/200 [00:12<00:15,  7.04it/s]\u001b[A\n",
      " 45%|████▌     | 90/200 [00:12<00:15,  7.04it/s]\u001b[A\n",
      " 46%|████▌     | 91/200 [00:12<00:15,  7.05it/s]\u001b[A\n",
      " 46%|████▌     | 92/200 [00:13<00:15,  7.06it/s]\u001b[A\n",
      " 46%|████▋     | 93/200 [00:13<00:15,  7.07it/s]\u001b[A\n",
      " 47%|████▋     | 94/200 [00:13<00:14,  7.08it/s]\u001b[A\n",
      " 48%|████▊     | 95/200 [00:13<00:14,  7.08it/s]\u001b[A\n",
      " 48%|████▊     | 96/200 [00:13<00:14,  7.09it/s]\u001b[A\n",
      " 48%|████▊     | 97/200 [00:13<00:14,  7.10it/s]\u001b[A\n",
      " 49%|████▉     | 98/200 [00:13<00:14,  7.10it/s]\u001b[A\n",
      " 50%|████▉     | 99/200 [00:13<00:14,  7.11it/s]\u001b[A\n",
      " 50%|█████     | 100/200 [00:14<00:14,  7.12it/s]\u001b[A\n",
      " 50%|█████     | 101/200 [00:14<00:13,  7.13it/s]\u001b[A\n",
      " 51%|█████     | 102/200 [00:14<00:13,  7.13it/s]\u001b[A\n",
      " 52%|█████▏    | 103/200 [00:14<00:13,  7.14it/s]\u001b[A\n",
      " 52%|█████▏    | 104/200 [00:14<00:13,  7.14it/s]\u001b[A\n",
      " 52%|█████▎    | 105/200 [00:14<00:13,  7.15it/s]\u001b[A\n",
      " 53%|█████▎    | 106/200 [00:14<00:13,  7.16it/s]\u001b[A\n",
      " 54%|█████▎    | 107/200 [00:14<00:12,  7.16it/s]\u001b[A\n",
      " 54%|█████▍    | 108/200 [00:15<00:12,  7.17it/s]\u001b[A\n",
      " 55%|█████▍    | 109/200 [00:15<00:12,  7.18it/s]\u001b[A\n",
      " 55%|█████▌    | 110/200 [00:15<00:12,  7.19it/s]\u001b[A\n",
      " 56%|█████▌    | 111/200 [00:15<00:12,  7.20it/s]\u001b[A\n",
      " 56%|█████▌    | 112/200 [00:15<00:12,  7.21it/s]\u001b[A\n",
      " 56%|█████▋    | 113/200 [00:15<00:12,  7.21it/s]\u001b[A\n",
      " 57%|█████▋    | 114/200 [00:15<00:11,  7.22it/s]\u001b[A\n",
      " 57%|█████▊    | 115/200 [00:15<00:11,  7.23it/s]\u001b[A\n",
      " 58%|█████▊    | 116/200 [00:16<00:11,  7.24it/s]\u001b[A\n",
      " 58%|█████▊    | 117/200 [00:16<00:11,  7.25it/s]\u001b[A\n",
      " 59%|█████▉    | 118/200 [00:16<00:11,  7.26it/s]\u001b[A\n",
      " 60%|█████▉    | 119/200 [00:16<00:11,  7.27it/s]\u001b[A\n",
      " 60%|██████    | 120/200 [00:16<00:10,  7.28it/s]\u001b[A\n",
      " 60%|██████    | 121/200 [00:16<00:10,  7.29it/s]\u001b[A\n",
      " 61%|██████    | 122/200 [00:16<00:10,  7.30it/s]\u001b[A\n",
      " 62%|██████▏   | 123/200 [00:16<00:10,  7.30it/s]\u001b[A\n",
      " 62%|██████▏   | 124/200 [00:16<00:10,  7.31it/s]\u001b[A\n",
      " 62%|██████▎   | 125/200 [00:17<00:10,  7.32it/s]\u001b[A\n",
      " 63%|██████▎   | 126/200 [00:17<00:10,  7.33it/s]\u001b[A\n",
      " 64%|██████▎   | 127/200 [00:17<00:09,  7.33it/s]\u001b[A\n",
      " 64%|██████▍   | 128/200 [00:17<00:09,  7.34it/s]\u001b[A\n",
      " 64%|██████▍   | 129/200 [00:17<00:09,  7.35it/s]\u001b[A\n",
      " 65%|██████▌   | 130/200 [00:17<00:09,  7.36it/s]\u001b[A\n",
      " 66%|██████▌   | 131/200 [00:17<00:09,  7.36it/s]\u001b[A\n",
      " 66%|██████▌   | 132/200 [00:17<00:09,  7.37it/s]\u001b[A\n",
      " 66%|██████▋   | 133/200 [00:18<00:09,  7.38it/s]\u001b[A\n",
      " 67%|██████▋   | 134/200 [00:18<00:08,  7.38it/s]\u001b[A\n",
      " 68%|██████▊   | 135/200 [00:18<00:08,  7.39it/s]\u001b[A\n",
      " 68%|██████▊   | 136/200 [00:18<00:08,  7.39it/s]\u001b[A\n",
      " 68%|██████▊   | 137/200 [00:18<00:08,  7.40it/s]\u001b[A\n",
      " 69%|██████▉   | 138/200 [00:18<00:08,  7.41it/s]\u001b[A\n",
      " 70%|██████▉   | 139/200 [00:18<00:08,  7.41it/s]\u001b[A\n",
      " 70%|███████   | 140/200 [00:18<00:08,  7.42it/s]\u001b[A\n",
      " 70%|███████   | 141/200 [00:18<00:07,  7.43it/s]\u001b[A\n",
      " 71%|███████   | 142/200 [00:19<00:07,  7.43it/s]\u001b[A\n",
      " 72%|███████▏  | 143/200 [00:19<00:07,  7.44it/s]\u001b[A\n",
      " 72%|███████▏  | 144/200 [00:19<00:07,  7.44it/s]\u001b[A\n",
      " 72%|███████▎  | 145/200 [00:19<00:07,  7.45it/s]\u001b[A\n",
      " 73%|███████▎  | 146/200 [00:19<00:07,  7.46it/s]\u001b[A\n",
      " 74%|███████▎  | 147/200 [00:19<00:07,  7.46it/s]\u001b[A\n",
      " 74%|███████▍  | 148/200 [00:19<00:06,  7.47it/s]\u001b[A\n",
      " 74%|███████▍  | 149/200 [00:19<00:06,  7.47it/s]\u001b[A\n",
      " 75%|███████▌  | 150/200 [00:20<00:06,  7.48it/s]\u001b[A\n",
      " 76%|███████▌  | 151/200 [00:20<00:06,  7.48it/s]\u001b[A\n",
      " 76%|███████▌  | 152/200 [00:20<00:06,  7.49it/s]\u001b[A\n",
      " 76%|███████▋  | 153/200 [00:20<00:06,  7.49it/s]\u001b[A\n",
      " 77%|███████▋  | 154/200 [00:20<00:06,  7.50it/s]\u001b[A\n",
      " 78%|███████▊  | 155/200 [00:20<00:05,  7.50it/s]\u001b[A\n",
      " 78%|███████▊  | 156/200 [00:20<00:05,  7.51it/s]\u001b[A\n",
      " 78%|███████▊  | 157/200 [00:20<00:05,  7.51it/s]\u001b[A\n",
      " 79%|███████▉  | 158/200 [00:21<00:05,  7.52it/s]\u001b[A\n",
      " 80%|███████▉  | 159/200 [00:21<00:05,  7.52it/s]\u001b[A\n",
      " 80%|████████  | 160/200 [00:21<00:05,  7.53it/s]\u001b[A\n",
      " 80%|████████  | 161/200 [00:21<00:05,  7.54it/s]\u001b[A\n",
      " 81%|████████  | 162/200 [00:21<00:05,  7.54it/s]\u001b[A\n",
      " 82%|████████▏ | 163/200 [00:21<00:04,  7.55it/s]\u001b[A\n",
      " 82%|████████▏ | 164/200 [00:21<00:04,  7.55it/s]\u001b[A\n",
      " 82%|████████▎ | 165/200 [00:21<00:04,  7.56it/s]\u001b[A\n",
      " 83%|████████▎ | 166/200 [00:21<00:04,  7.56it/s]\u001b[A\n",
      " 84%|████████▎ | 167/200 [00:22<00:04,  7.57it/s]\u001b[A\n",
      " 84%|████████▍ | 168/200 [00:22<00:04,  7.58it/s]\u001b[A\n",
      " 84%|████████▍ | 169/200 [00:22<00:04,  7.58it/s]\u001b[A\n",
      " 85%|████████▌ | 170/200 [00:22<00:03,  7.59it/s]\u001b[A\n",
      " 86%|████████▌ | 171/200 [00:22<00:03,  7.59it/s]\u001b[A\n",
      " 86%|████████▌ | 172/200 [00:22<00:03,  7.60it/s]\u001b[A\n",
      " 86%|████████▋ | 173/200 [00:22<00:03,  7.60it/s]\u001b[A\n",
      " 87%|████████▋ | 174/200 [00:22<00:03,  7.61it/s]\u001b[A\n",
      " 88%|████████▊ | 175/200 [00:22<00:03,  7.61it/s]\u001b[A\n",
      " 88%|████████▊ | 176/200 [00:23<00:03,  7.62it/s]\u001b[A\n",
      " 88%|████████▊ | 177/200 [00:23<00:03,  7.62it/s]\u001b[A\n",
      " 89%|████████▉ | 178/200 [00:23<00:02,  7.63it/s]\u001b[A\n",
      " 90%|████████▉ | 179/200 [00:23<00:02,  7.63it/s]\u001b[A\n",
      " 90%|█████████ | 180/200 [00:23<00:02,  7.64it/s]\u001b[A\n",
      " 90%|█████████ | 181/200 [00:23<00:02,  7.64it/s]\u001b[A\n",
      " 91%|█████████ | 182/200 [00:23<00:02,  7.65it/s]\u001b[A\n",
      " 92%|█████████▏| 183/200 [00:23<00:02,  7.65it/s]\u001b[A\n",
      " 92%|█████████▏| 184/200 [00:24<00:02,  7.66it/s]\u001b[A\n",
      " 92%|█████████▎| 185/200 [00:24<00:01,  7.66it/s]\u001b[A\n",
      " 93%|█████████▎| 186/200 [00:24<00:01,  7.66it/s]\u001b[A\n",
      " 94%|█████████▎| 187/200 [00:24<00:01,  7.67it/s]\u001b[A\n",
      " 94%|█████████▍| 188/200 [00:24<00:01,  7.67it/s]\u001b[A\n",
      " 94%|█████████▍| 189/200 [00:24<00:01,  7.68it/s]\u001b[A\n",
      " 95%|█████████▌| 190/200 [00:24<00:01,  7.68it/s]\u001b[A\n",
      " 96%|█████████▌| 191/200 [00:24<00:01,  7.69it/s]\u001b[A\n",
      " 96%|█████████▌| 192/200 [00:24<00:01,  7.69it/s]\u001b[A\n",
      " 96%|█████████▋| 193/200 [00:25<00:00,  7.70it/s]\u001b[A\n",
      " 97%|█████████▋| 194/200 [00:25<00:00,  7.70it/s]\u001b[A\n",
      " 98%|█████████▊| 195/200 [00:25<00:00,  7.70it/s]\u001b[A\n",
      " 98%|█████████▊| 196/200 [00:25<00:00,  7.71it/s]\u001b[A\n",
      " 98%|█████████▊| 197/200 [00:25<00:00,  7.71it/s]\u001b[A\n",
      " 99%|█████████▉| 198/200 [00:25<00:00,  7.72it/s]\u001b[A\n",
      "100%|█████████▉| 199/200 [00:25<00:00,  7.72it/s]\u001b[A\n",
      "100%|██████████| 200/200 [00:25<00:00,  7.72it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(   X_training[:, :2000],\n",
    "                                                                                    Y_training[:, :2000],\n",
    "                                                                                    X_validation[:, :2000],\n",
    "                                                                                    Y_validation[:, :2000],\n",
    "                                                                                    [], [],\n",
    "                                                                                    GD_params,\n",
    "                                                                                    W1, b1, W2, b2,\n",
    "                                                                                    regularization_term=0,\n",
    "                                                                                    momentum_term=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_costs(training_set_loss, validation_set_loss, display=True, title='Cross Entropy Loss Evolution with momentum value: 0.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 4/200 [00:00<00:05, 37.19it/s]\u001b[A\n",
      "  4%|▍         | 8/200 [00:00<00:05, 37.51it/s]\u001b[A\n",
      "  6%|▌         | 12/200 [00:00<00:05, 37.55it/s]\u001b[A\n",
      "  8%|▊         | 16/200 [00:00<00:04, 37.75it/s]\u001b[A\n",
      " 10%|█         | 20/200 [00:00<00:04, 37.94it/s]\u001b[A\n",
      " 12%|█▏        | 24/200 [00:00<00:04, 38.20it/s]\u001b[A\n",
      " 14%|█▍        | 28/200 [00:00<00:04, 38.40it/s]\u001b[A\n",
      " 16%|█▌        | 32/200 [00:00<00:04, 38.53it/s]\u001b[A\n",
      " 18%|█▊        | 36/200 [00:00<00:04, 38.65it/s]\u001b[A\n",
      " 20%|██        | 40/200 [00:01<00:04, 38.78it/s]\u001b[A\n",
      " 22%|██▏       | 44/200 [00:01<00:04, 38.56it/s]\u001b[A\n",
      " 24%|██▍       | 48/200 [00:01<00:04, 37.81it/s]\u001b[A\n",
      " 26%|██▌       | 52/200 [00:01<00:03, 37.07it/s]\u001b[A\n",
      " 28%|██▊       | 56/200 [00:01<00:03, 36.58it/s]\u001b[A\n",
      " 30%|███       | 60/200 [00:01<00:03, 36.01it/s]\u001b[A\n",
      " 32%|███▏      | 64/200 [00:01<00:03, 36.06it/s]\u001b[A\n",
      " 34%|███▍      | 68/200 [00:01<00:03, 36.17it/s]\u001b[A\n",
      " 36%|███▌      | 72/200 [00:01<00:03, 36.27it/s]\u001b[A\n",
      " 38%|███▊      | 76/200 [00:02<00:03, 35.96it/s]\u001b[A\n",
      " 40%|████      | 80/200 [00:02<00:03, 36.05it/s]\u001b[A\n",
      " 42%|████▏     | 84/200 [00:02<00:03, 36.21it/s]\u001b[A\n",
      " 44%|████▍     | 88/200 [00:02<00:03, 36.33it/s]\u001b[A\n",
      " 46%|████▌     | 92/200 [00:02<00:02, 36.36it/s]\u001b[A\n",
      " 48%|████▊     | 96/200 [00:02<00:02, 36.41it/s]\u001b[A\n",
      " 50%|█████     | 101/200 [00:02<00:02, 36.60it/s]\u001b[A\n",
      " 52%|█████▎    | 105/200 [00:02<00:02, 36.68it/s]\u001b[A\n",
      " 55%|█████▍    | 109/200 [00:02<00:02, 36.78it/s]\u001b[A\n",
      " 56%|█████▋    | 113/200 [00:03<00:02, 36.86it/s]\u001b[A\n",
      " 58%|█████▊    | 117/200 [00:03<00:02, 36.91it/s]\u001b[A\n",
      " 60%|██████    | 121/200 [00:03<00:02, 36.99it/s]\u001b[A\n",
      " 62%|██████▎   | 125/200 [00:03<00:02, 37.05it/s]\u001b[A\n",
      " 64%|██████▍   | 129/200 [00:03<00:01, 37.10it/s]\u001b[A\n",
      " 66%|██████▋   | 133/200 [00:03<00:01, 37.16it/s]\u001b[A\n",
      " 68%|██████▊   | 137/200 [00:03<00:01, 37.22it/s]\u001b[A\n",
      " 70%|███████   | 141/200 [00:03<00:01, 37.12it/s]\u001b[A\n",
      " 72%|███████▎  | 145/200 [00:03<00:01, 36.90it/s]\u001b[A\n",
      " 74%|███████▍  | 149/200 [00:04<00:01, 36.68it/s]\u001b[A\n",
      " 76%|███████▋  | 153/200 [00:04<00:01, 36.47it/s]\u001b[A\n",
      " 78%|███████▊  | 157/200 [00:04<00:01, 36.52it/s]\u001b[A\n",
      " 80%|████████  | 161/200 [00:04<00:01, 36.39it/s]\u001b[A\n",
      " 82%|████████▎ | 165/200 [00:04<00:00, 36.25it/s]\u001b[A\n",
      " 84%|████████▍ | 169/200 [00:04<00:00, 36.31it/s]\u001b[A\n",
      " 86%|████████▋ | 173/200 [00:04<00:00, 36.35it/s]\u001b[A\n",
      " 88%|████████▊ | 177/200 [00:04<00:00, 36.40it/s]\u001b[A\n",
      " 90%|█████████ | 181/200 [00:04<00:00, 36.39it/s]\u001b[A\n",
      " 92%|█████████▎| 185/200 [00:05<00:00, 36.35it/s]\u001b[A\n",
      " 94%|█████████▍| 189/200 [00:05<00:00, 36.32it/s]\u001b[A\n",
      " 96%|█████████▋| 193/200 [00:05<00:00, 36.32it/s]\u001b[A\n",
      " 98%|█████████▊| 197/200 [00:05<00:00, 36.34it/s]\u001b[A\n",
      "100%|██████████| 200/200 [00:05<00:00, 36.37it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(   X_training[:, :500],\n",
    "                                                                                    Y_training[:, :500],\n",
    "                                                                                    X_validation[:, :500],\n",
    "                                                                                    Y_validation[:, :500],\n",
    "                                                                                    [], [],\n",
    "                                                                                    GD_params,\n",
    "                                                                                    W1, b1, W2, b2,\n",
    "                                                                                    regularization_term=0,\n",
    "                                                                                    momentum_term=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_costs(training_set_loss, validation_set_loss, display=True, title='Cross Entropy Loss Evolution with momentum value: 0.5', save_name='3_momentum_0-5', save_path='../figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Training your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search():\n",
    "    \"\"\"\n",
    "    Random search to estimate the rough bounds for the values to eta to look for later in the coarse search.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    training_data, validation_data, test_data, W1, b1, W2, b2 = exercise_1()\n",
    "    X_training, Y_training, y_training = training_data\n",
    "    X_validation, Y_validation, y_validation = validation_data\n",
    "\n",
    "    for eta in [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "\n",
    "        print('-----------------------')\n",
    "        print('eta: ', eta)\n",
    "\n",
    "        GD_params = [100, eta, 5]\n",
    "\n",
    "        W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                         Y_training,\n",
    "                                                                                         X_validation,\n",
    "                                                                                         Y_validation,\n",
    "                                                                                         y_validation,\n",
    "                                                                                         GD_params,\n",
    "                                                                                         W1, b1, W2, b2,\n",
    "                                                                                         regularization_term=0.000001,\n",
    "                                                                                         momentum_term=0.9)\n",
    "\n",
    "        W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "#             visualize_single_cost(training_set_loss, display=False, title='Training set loss evolution for eta: '+str(eta), save_name='Eta_random_'+str(eta).replace('.', '-'))\n",
    "\n",
    "    for eta in np.arange(0.2, 0.5, 0.05):\n",
    "\n",
    "        print('-----------------------')\n",
    "        print('eta: ', eta)\n",
    "\n",
    "        GD_params = [100, eta, 5]\n",
    "\n",
    "        W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                         Y_training,\n",
    "                                                                                         X_validation,\n",
    "                                                                                         Y_validation,\n",
    "                                                                                         y_validation,\n",
    "                                                                                         GD_params,\n",
    "                                                                                         W1, b1, W2, b2,\n",
    "                                                                                         regularization_term=0.000001,\n",
    "                                                                                         momentum_term=0.9)\n",
    "\n",
    "        W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "#             visualize_single_cost(training_set_loss, display=False, title='Training set loss evolution for eta: '+str(eta), save_name='Eta_random_'+str(eta).replace('.', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "eta:  1e-05\n",
      "Training set loss after epoch number 0 is: 2.3025848506920643\n",
      "Training set loss after epoch number 1 is: 2.302583841443368\n",
      "Training set loss after epoch number 2 is: 2.3025828840707727\n",
      "Training set loss after epoch number 3 is: 2.3025819761862096\n",
      "Training set loss after epoch number 4 is: 2.3025811148946467\n",
      "-----------------------\n",
      "eta:  5e-05\n",
      "Training set loss after epoch number 0 is: 2.302581166802597\n",
      "Training set loss after epoch number 1 is: 2.3025761599923698\n",
      "Training set loss after epoch number 2 is: 2.3025714319240826\n",
      "Training set loss after epoch number 3 is: 2.302566964345669\n",
      "Training set loss after epoch number 4 is: 2.3025627410959992\n",
      "-----------------------\n",
      "eta:  0.0001\n",
      "Training set loss after epoch number 0 is: 2.30257658291642\n",
      "Training set loss after epoch number 1 is: 2.302566649200436\n",
      "Training set loss after epoch number 2 is: 2.3025573099186\n",
      "Training set loss after epoch number 3 is: 2.302548512635035\n",
      "Training set loss after epoch number 4 is: 2.3025401957678024\n",
      "-----------------------\n",
      "eta:  0.0005\n",
      "Training set loss after epoch number 0 is: 2.302540587592968\n",
      "Training set loss after epoch number 1 is: 2.302491988907828\n",
      "Training set loss after epoch number 2 is: 2.3024428255480847\n",
      "Training set loss after epoch number 3 is: 2.3023886927860806\n",
      "Training set loss after epoch number 4 is: 2.3023246072972063\n",
      "-----------------------\n",
      "eta:  0.001\n",
      "Training set loss after epoch number 0 is: 2.3024961118640817\n",
      "Training set loss after epoch number 1 is: 2.302385974069006\n",
      "Training set loss after epoch number 2 is: 2.3022182701771743\n",
      "Training set loss after epoch number 3 is: 2.301887819606671\n",
      "Training set loss after epoch number 4 is: 2.3011638049174845\n",
      "-----------------------\n",
      "eta:  0.005\n",
      "Training set loss after epoch number 0 is: 2.3016173556298125\n",
      "Training set loss after epoch number 1 is: 2.2550413596396766\n",
      "Training set loss after epoch number 2 is: 2.1146773986603358\n",
      "Training set loss after epoch number 3 is: 2.017094492085483\n",
      "Training set loss after epoch number 4 is: 1.9535316378904555\n",
      "-----------------------\n",
      "eta:  0.01\n",
      "Training set loss after epoch number 0 is: 2.2827034244596045\n",
      "Training set loss after epoch number 1 is: 2.0367023475847756\n",
      "Training set loss after epoch number 2 is: 1.9087574123414015\n",
      "Training set loss after epoch number 3 is: 1.8115696768818903\n",
      "Training set loss after epoch number 4 is: 1.746466464568492\n",
      "-----------------------\n",
      "eta:  0.05\n",
      "Training set loss after epoch number 0 is: 1.8631283357230615\n",
      "Training set loss after epoch number 1 is: 1.6802545089198524\n",
      "Training set loss after epoch number 2 is: 1.5561225480297545\n",
      "Training set loss after epoch number 3 is: 1.48447438398465\n",
      "Training set loss after epoch number 4 is: 1.3948883159995926\n",
      "-----------------------\n",
      "eta:  0.1\n",
      "Training set loss after epoch number 0 is: 1.7809084849468708\n",
      "Training set loss after epoch number 1 is: 1.647158691489011\n",
      "Training set loss after epoch number 2 is: 1.576782693391572\n",
      "Training set loss after epoch number 3 is: 1.5048117377048429\n",
      "Training set loss after epoch number 4 is: 1.4282937238930191\n",
      "-----------------------\n",
      "eta:  0.2\n",
      "Training set loss after epoch number 0 is: 1.896857875221071\n",
      "Training set loss after epoch number 1 is: 1.8297946613480636\n",
      "Training set loss after epoch number 2 is: 1.8206863209161308\n",
      "Training set loss after epoch number 3 is: 1.7364877149056364\n",
      "Training set loss after epoch number 4 is: 1.6740169282547976\n",
      "-----------------------\n",
      "eta:  0.25\n",
      "Training set loss after epoch number 0 is: 2.1669436732078977\n",
      "Training set loss after epoch number 1 is: 2.1036145243458817\n",
      "Training set loss after epoch number 2 is: 1.8602258627275428\n",
      "Training set loss after epoch number 3 is: 1.8931909598326608\n",
      "Training set loss after epoch number 4 is: 1.7214404964776455\n",
      "-----------------------\n",
      "eta:  0.3\n",
      "Training set loss after epoch number 0 is: 3.8002923593685707\n",
      "Training set loss after epoch number 1 is: 2.373464657161541\n",
      "Training set loss after epoch number 2 is: 2.0204059748019203\n",
      "Training set loss after epoch number 3 is: 1.9318048338288314\n",
      "Training set loss after epoch number 4 is: 1.9017615995219335\n",
      "-----------------------\n",
      "eta:  0.35\n",
      "Training set loss after epoch number 0 is: 7.4996254964050575\n",
      "-----------------------\n",
      "eta:  0.39999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set loss after epoch number 0 is: inf\n",
      "-----------------------\n",
      "eta:  0.44999999999999996\n",
      "Training set loss after epoch number 0 is: inf\n"
     ]
    }
   ],
   "source": [
    "random_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coarse search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse_search(e_min= np.log(0.01), e_max=np.log(0.15)):\n",
    "    \"\"\"\n",
    "    Coarse search, optimal value for the learning rate may be found between 0.01 and 0.15\n",
    "\n",
    "    :return: Best pair of eta and lambda based on validation set accuracy performance\n",
    "    \"\"\"\n",
    "\n",
    "    training_data, validation_data, test_data, W1, b1, W2, b2 = exercise_1()\n",
    "    X_training, Y_training, y_training = training_data\n",
    "    X_validation, Y_validation, y_validation = validation_data\n",
    "\n",
    "    accuracies = []\n",
    "    etas = []\n",
    "    lambdas = []\n",
    "\n",
    "    for regularization_term in [0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-3, 1e-1, 1]:\n",
    "\n",
    "        for _ in range(12):\n",
    "            np.random.seed()\n",
    "            eta_term = np.random.rand(1, 1).flatten()[0]\n",
    "            e = e_min + (e_max - e_min) * eta_term\n",
    "            eta = np.exp(e)\n",
    "            etas.append(eta)\n",
    "\n",
    "            lambdas.append(regularization_term)\n",
    "\n",
    "            GD_params = [100, eta, 10]\n",
    "\n",
    "            W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                             Y_training,\n",
    "                                                                                             X_validation,\n",
    "                                                                                             Y_validation,\n",
    "                                                                                             GD_params,\n",
    "                                                                                             W1, b1, W2, b2,\n",
    "                                                                                             regularization_term=regularization_term)\n",
    "            print('---------------------------------')\n",
    "            print('Learning rate: '+str(eta)+', amount of regularization term: '+str(regularization_term))\n",
    "            accuracy_on_validation_set = ComputeAccuracy(X_validation, y_validation, W1, b1, W2, b2)\n",
    "            accuracies.append(accuracy_on_validation_set)\n",
    "            print('Accuracy performance on the validation set: ', accuracy_on_validation_set)\n",
    "\n",
    "            W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "    sort_them_all = sorted(zip(accuracies, etas, lambdas))\n",
    "\n",
    "    best_accuracies = [x for x, _ , _ in sort_them_all]\n",
    "    best_etas = [y for _, y , _ in sort_them_all]\n",
    "    best_lambdas = [z for _, _ , z in sort_them_all]\n",
    "\n",
    "    print('---------------------------------')\n",
    "    print('BEST PERFORMANCE: ', str(best_accuracies[-1]))\n",
    "    print('Best eta: ', best_etas[-1])\n",
    "    print('Best lambda: ', best_lambdas[-1])\n",
    "\n",
    "    print('---------------------------------')\n",
    "    print('SECOND BEST PERFORMANCE: ', str(best_accuracies[-2]))\n",
    "    print('Second best eta: ', best_etas[-2])\n",
    "    print('Second best lambda: ', best_lambdas[-2])\n",
    "\n",
    "    print('---------------------------------')\n",
    "    print('THIRD BEST PERFORMANCE: ', str(best_accuracies[-3]))\n",
    "    print('Third best eta: ', best_etas[-3])\n",
    "    print('Third best lambda: ', best_lambdas[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Learning rate: 0.01682656011091022, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  42.83\n",
      "---------------------------------\n",
      "Learning rate: 0.08147359655297683, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  39.43\n",
      "---------------------------------\n",
      "Learning rate: 0.0475448802275006, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  41.67\n",
      "---------------------------------\n",
      "Learning rate: 0.043287479050267516, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  42.23\n",
      "---------------------------------\n",
      "Learning rate: 0.038164956302654054, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  42.99\n",
      "---------------------------------\n",
      "Learning rate: 0.04900996226997768, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  41.29\n",
      "---------------------------------\n",
      "Learning rate: 0.09907513432084375, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  39.41\n",
      "---------------------------------\n",
      "Learning rate: 0.011686139933991247, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  41.68\n",
      "---------------------------------\n",
      "Learning rate: 0.017519035299645536, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  43.08\n",
      "---------------------------------\n",
      "Learning rate: 0.04733163471721282, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  41.17\n",
      "---------------------------------\n",
      "Learning rate: 0.05656525549039319, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  40.68\n",
      "---------------------------------\n",
      "Learning rate: 0.14319412422134728, amount of regularization term: 0\n",
      "Accuracy performance on the validation set:  37.3\n",
      "---------------------------------\n",
      "Learning rate: 0.04019804454500277, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  42.98\n",
      "---------------------------------\n",
      "Learning rate: 0.016794085685579822, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  42.76\n",
      "---------------------------------\n",
      "Learning rate: 0.016083881828390555, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  43.17\n",
      "---------------------------------\n",
      "Learning rate: 0.07571438698597516, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  40.09\n",
      "---------------------------------\n",
      "Learning rate: 0.05360049225223563, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  41.37\n",
      "---------------------------------\n",
      "Learning rate: 0.04900355912791014, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  42.31\n",
      "---------------------------------\n",
      "Learning rate: 0.028146826880188, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  43.52\n",
      "---------------------------------\n",
      "Learning rate: 0.048629891920509975, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  42.05\n",
      "---------------------------------\n",
      "Learning rate: 0.05921185474237473, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  40.38\n",
      "---------------------------------\n",
      "Learning rate: 0.024547983475131686, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  43.03\n",
      "---------------------------------\n",
      "Learning rate: 0.017653247956974486, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  42.94\n",
      "---------------------------------\n",
      "Learning rate: 0.018928620403206566, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  43.43\n",
      "---------------------------------\n",
      "Learning rate: 0.031164324760240503, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  43.16\n",
      "---------------------------------\n",
      "Learning rate: 0.033973230476599725, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  42.69\n",
      "---------------------------------\n",
      "Learning rate: 0.10254166570899542, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.08\n",
      "---------------------------------\n",
      "Learning rate: 0.023202317163829908, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  43.56\n",
      "---------------------------------\n",
      "Learning rate: 0.10855752415441641, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.52\n",
      "---------------------------------\n",
      "Learning rate: 0.049486840179501376, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  41.19\n",
      "---------------------------------\n",
      "Learning rate: 0.03179840421420566, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  43.55\n",
      "---------------------------------\n",
      "Learning rate: 0.01551083226516291, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  42.73\n",
      "---------------------------------\n",
      "Learning rate: 0.02534053640834971, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  43.91\n",
      "---------------------------------\n",
      "Learning rate: 0.04210638332625914, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  42.66\n",
      "---------------------------------\n",
      "Learning rate: 0.015178329624306229, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  42.82\n",
      "---------------------------------\n",
      "Learning rate: 0.03291033617986169, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  42.97\n",
      "---------------------------------\n",
      "Learning rate: 0.054879625730251035, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  40.95\n",
      "---------------------------------\n",
      "Learning rate: 0.010861663856138104, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  41.24\n",
      "---------------------------------\n",
      "Learning rate: 0.010379502644722469, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  41.42\n",
      "---------------------------------\n",
      "Learning rate: 0.06053548823296675, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  40.7\n",
      "---------------------------------\n",
      "Learning rate: 0.01837583023272926, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.31\n",
      "---------------------------------\n",
      "Learning rate: 0.056858783704962716, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  40.67\n",
      "---------------------------------\n",
      "Learning rate: 0.06009443887505436, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  41.39\n",
      "---------------------------------\n",
      "Learning rate: 0.019167560702978606, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.14\n",
      "---------------------------------\n",
      "Learning rate: 0.04539492448976539, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.29\n",
      "---------------------------------\n",
      "Learning rate: 0.138688787102051, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  38.5\n",
      "---------------------------------\n",
      "Learning rate: 0.015908661291381975, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.94\n",
      "---------------------------------\n",
      "Learning rate: 0.018907791676209398, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.43\n",
      "---------------------------------\n",
      "Learning rate: 0.04994912409378349, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  42.53\n",
      "---------------------------------\n",
      "Learning rate: 0.04826242372420252, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  42.27\n",
      "---------------------------------\n",
      "Learning rate: 0.02943170892939651, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.09\n",
      "---------------------------------\n",
      "Learning rate: 0.014913600850622337, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  42.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Learning rate: 0.04521203024064449, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  42.36\n",
      "---------------------------------\n",
      "Learning rate: 0.05676789861851565, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  41.22\n",
      "---------------------------------\n",
      "Learning rate: 0.018800130793788727, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.22\n",
      "---------------------------------\n",
      "Learning rate: 0.03081995705702969, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.77\n",
      "---------------------------------\n",
      "Learning rate: 0.01843306331980966, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.12\n",
      "---------------------------------\n",
      "Learning rate: 0.012499263976140852, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  42.22\n",
      "---------------------------------\n",
      "Learning rate: 0.030378861572303927, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.56\n",
      "---------------------------------\n",
      "Learning rate: 0.05079411511126532, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  42.12\n",
      "---------------------------------\n",
      "Learning rate: 0.030687177183315043, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.99\n",
      "---------------------------------\n",
      "Learning rate: 0.010189665662864767, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  41.03\n",
      "---------------------------------\n",
      "Learning rate: 0.021318066304353626, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.39\n",
      "---------------------------------\n",
      "Learning rate: 0.022467027269745574, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.66\n",
      "---------------------------------\n",
      "Learning rate: 0.027321758826846766, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.6\n",
      "---------------------------------\n",
      "Learning rate: 0.09891438553772101, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.55\n",
      "---------------------------------\n",
      "Learning rate: 0.10174727962157734, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  38.78\n",
      "---------------------------------\n",
      "Learning rate: 0.05593741729160568, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  41.94\n",
      "---------------------------------\n",
      "Learning rate: 0.016495023956004305, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  42.87\n",
      "---------------------------------\n",
      "Learning rate: 0.02878809988519304, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  44.07\n",
      "---------------------------------\n",
      "Learning rate: 0.12550474812525625, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.27\n",
      "---------------------------------\n",
      "Learning rate: 0.07333912687434561, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.41\n",
      "---------------------------------\n",
      "Learning rate: 0.028255036480758507, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  24.7\n",
      "---------------------------------\n",
      "Learning rate: 0.010708396479081962, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  23.46\n",
      "---------------------------------\n",
      "Learning rate: 0.06379632007013931, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  23.13\n",
      "---------------------------------\n",
      "Learning rate: 0.13795807934911353, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  20.77\n",
      "---------------------------------\n",
      "Learning rate: 0.07588635931581976, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  22.37\n",
      "---------------------------------\n",
      "Learning rate: 0.13178990760457537, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  20.84\n",
      "---------------------------------\n",
      "Learning rate: 0.08452665757283993, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  21.88\n",
      "---------------------------------\n",
      "Learning rate: 0.05023907690676868, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  23.62\n",
      "---------------------------------\n",
      "Learning rate: 0.10363623467898764, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  22.39\n",
      "---------------------------------\n",
      "Learning rate: 0.03464417283015146, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  25.0\n",
      "---------------------------------\n",
      "Learning rate: 0.06593471633768254, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  23.17\n",
      "---------------------------------\n",
      "Learning rate: 0.02743138636427112, amount of regularization term: 0.1\n",
      "Accuracy performance on the validation set:  24.79\n",
      "---------------------------------\n",
      "Learning rate: 0.04202972648929199, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.95\n",
      "---------------------------------\n",
      "Learning rate: 0.05008693593833101, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.95\n",
      "---------------------------------\n",
      "Learning rate: 0.08897933057626109, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.95\n",
      "---------------------------------\n",
      "Learning rate: 0.03762429744581556, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.95\n",
      "---------------------------------\n",
      "Learning rate: 0.09389941977949179, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.95\n",
      "---------------------------------\n",
      "Learning rate: 0.14756332290319127, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  10.07\n",
      "---------------------------------\n",
      "Learning rate: 0.021494380249831607, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.87\n",
      "---------------------------------\n",
      "Learning rate: 0.028875238745669603, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.95\n",
      "---------------------------------\n",
      "Learning rate: 0.026433831992196736, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.87\n",
      "---------------------------------\n",
      "Learning rate: 0.048884766775920005, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.95\n",
      "---------------------------------\n",
      "Learning rate: 0.01962453073060799, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.87\n",
      "---------------------------------\n",
      "Learning rate: 0.015795002915286058, amount of regularization term: 1\n",
      "Accuracy performance on the validation set:  9.87\n",
      "---------------------------------\n",
      "BEST PERFORMANCE:  44.07\n",
      "Best eta:  0.02878809988519304\n",
      "Best lambda:  0.001\n",
      "---------------------------------\n",
      "SECOND BEST PERFORMANCE:  43.99\n",
      "Second best eta:  0.030687177183315043\n",
      "Second best lambda:  0.001\n",
      "---------------------------------\n",
      "THIRD BEST PERFORMANCE:  43.91\n",
      "Third best eta:  0.02534053640834971\n",
      "Third best lambda:  1e-05\n"
     ]
    }
   ],
   "source": [
    "coarse_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_search():\n",
    "    \"\"\"\n",
    "    Fine search, where we examine the most interesting pairings that were observed during the coarse search.\n",
    "\n",
    "    :return: accuracies, etas and lambdas of the search\n",
    "    \"\"\"\n",
    "\n",
    "    training_data, validation_data, test_data, W1, b1, W2, b2 = exercise_1()\n",
    "    X_training, Y_training, y_training = training_data\n",
    "    X_validation, Y_validation, y_validation = validation_data\n",
    "\n",
    "    accuracies = []\n",
    "    etas = []\n",
    "    lambdas = []\n",
    "\n",
    "    # For a regularization amount as small as 1e-6, the closest to a 44% validation set\n",
    "    # accuracy performance was spotted for values of eta ~[0.18, 0.28]\n",
    "    regularization_term = 1e-6\n",
    "\n",
    "    W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "    for _ in range(10):\n",
    "        np.random.seed()\n",
    "        eta_term = np.random.rand(1, 1).flatten()[0]\n",
    "        e_min = np.log(0.017)\n",
    "        e_max = np.log(0.019)\n",
    "        e = e_min + (e_max - e_min) * eta_term\n",
    "        eta = np.exp(e)\n",
    "        etas.append(eta)\n",
    "\n",
    "        lambdas.append(regularization_term)\n",
    "\n",
    "        GD_params = [100, eta, 10]\n",
    "\n",
    "        W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                         Y_training,\n",
    "                                                                                         X_validation,\n",
    "                                                                                         Y_validation,\n",
    "                                                                                         y_validation,\n",
    "                                                                                         GD_params,\n",
    "                                                                                         W1, b1, W2, b2,\n",
    "                                                                                         regularization_term=regularization_term)\n",
    "        print('---------------------------------')\n",
    "        print('Learning rate: ' + str(eta) + ', amount of regularization term: ' + str(regularization_term))\n",
    "        accuracy_on_validation_set = ComputeAccuracy(X_validation, y_validation, W1, b1, W2, b2)\n",
    "        accuracies.append(accuracy_on_validation_set)\n",
    "        print('Accuracy performance on the validation set: ', accuracy_on_validation_set)\n",
    "        \n",
    "    W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "    for _ in range(10):\n",
    "        np.random.seed()\n",
    "        eta_term = np.random.rand(1, 1).flatten()[0]\n",
    "        e_min = np.log(0.027)\n",
    "        e_max = np.log(0.029)\n",
    "        e = e_min + (e_max - e_min) * eta_term\n",
    "        eta = np.exp(e)\n",
    "        etas.append(eta)\n",
    "\n",
    "        lambdas.append(regularization_term)\n",
    "\n",
    "        GD_params = [100, eta, 10]\n",
    "\n",
    "        W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                         Y_training,\n",
    "                                                                                         X_validation,\n",
    "                                                                                         Y_validation,\n",
    "                                                                                         y_validation,\n",
    "                                                                                         GD_params,\n",
    "                                                                                         W1, b1, W2, b2,\n",
    "                                                                                         regularization_term=regularization_term)\n",
    "        print('---------------------------------')\n",
    "        print('Learning rate: ' + str(eta) + ', amount of regularization term: ' + str(regularization_term))\n",
    "        accuracy_on_validation_set = ComputeAccuracy(X_validation, y_validation, W1, b1, W2, b2)\n",
    "        accuracies.append(accuracy_on_validation_set)\n",
    "        print('Accuracy performance on the validation set: ', accuracy_on_validation_set)\n",
    "        \n",
    "    # For a regularization amount as small as 1e-5, the closest to a 44% validation set\n",
    "    # accuracy performance was spotted for values of eta ~[0.22, 0.25]\n",
    "    regularization_term = 1e-5\n",
    "    \n",
    "    W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "    for _ in range(20):\n",
    "        np.random.seed()\n",
    "        eta_term = np.random.rand(1, 1).flatten()[0]\n",
    "        e_min = np.log(0.022)\n",
    "        e_max = np.log(0.027)\n",
    "        e = e_min + (e_max - e_min) * eta_term\n",
    "        eta = np.exp(e)\n",
    "        etas.append(eta)\n",
    "\n",
    "        lambdas.append(regularization_term)\n",
    "\n",
    "        GD_params = [100, eta, 10]\n",
    "\n",
    "        W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                         Y_training,\n",
    "                                                                                         X_validation,\n",
    "                                                                                         Y_validation,\n",
    "                                                                                         y_validation,\n",
    "                                                                                         GD_params,\n",
    "                                                                                         W1, b1, W2, b2,\n",
    "                                                                                         regularization_term=regularization_term)\n",
    "        print('---------------------------------')\n",
    "        print('Learning rate: ' + str(eta) + ', amount of regularization term: ' + str(regularization_term))\n",
    "        accuracy_on_validation_set = ComputeAccuracy(X_validation, y_validation, W1, b1, W2, b2)\n",
    "        accuracies.append(accuracy_on_validation_set)\n",
    "        print('Accuracy performance on the validation set: ', accuracy_on_validation_set)\n",
    "\n",
    "    # For a regularization amount as high as 1e-4, the closest to a 44% validation set\n",
    "    # accuracy performance was spotted for values of eta ~0.18\n",
    "    regularization_term = 1e-4\n",
    "    \n",
    "    W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "    for _ in range(10):\n",
    "        np.random.seed()\n",
    "        eta_term = np.random.rand(1, 1).flatten()[0]\n",
    "        e_min = np.log(0.017)\n",
    "        e_max = np.log(0.019)\n",
    "        e = e_min + (e_max - e_min) * eta_term\n",
    "        eta = np.exp(e)\n",
    "        etas.append(eta)\n",
    "\n",
    "        lambdas.append(regularization_term)\n",
    "\n",
    "        GD_params = [100, eta, 10]\n",
    "\n",
    "        W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                         Y_training,\n",
    "                                                                                         X_validation,\n",
    "                                                                                         Y_validation,\n",
    "                                                                                         y_validation,\n",
    "                                                                                         GD_params,\n",
    "                                                                                         W1, b1, W2, b2,\n",
    "                                                                                         regularization_term=regularization_term)\n",
    "        print('---------------------------------')\n",
    "        print('Learning rate: ' + str(eta) + ', amount of regularization term: ' + str(regularization_term))\n",
    "        accuracy_on_validation_set = ComputeAccuracy(X_validation, y_validation, W1, b1, W2, b2)\n",
    "        accuracies.append(accuracy_on_validation_set)\n",
    "        print('Accuracy performance on the validation set: ', accuracy_on_validation_set)\n",
    "        \n",
    "    # For a regularization amount as high as 1e-3, the closest to a 44% validation set\n",
    "    # accuracy performance was spotted for values of eta ~0.28 and eta ~0.3\n",
    "    regularization_term = 1e-3\n",
    "    \n",
    "    W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "    for _ in range(20):\n",
    "        np.random.seed()\n",
    "        eta_term = np.random.rand(1, 1).flatten()[0]\n",
    "        e_min = np.log(0.028)\n",
    "        e_max = np.log(0.032)\n",
    "        e = e_min + (e_max - e_min) * eta_term\n",
    "        eta = np.exp(e)\n",
    "        etas.append(eta)\n",
    "\n",
    "        lambdas.append(regularization_term)\n",
    "\n",
    "        GD_params = [100, eta, 10]\n",
    "\n",
    "        W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                         Y_training,\n",
    "                                                                                         X_validation,\n",
    "                                                                                         Y_validation,\n",
    "                                                                                         y_validation,\n",
    "                                                                                         GD_params,\n",
    "                                                                                         W1, b1, W2, b2,\n",
    "                                                                                         regularization_term=regularization_term)\n",
    "        print('---------------------------------')\n",
    "        print('Learning rate: ' + str(eta) + ', amount of regularization term: ' + str(regularization_term))\n",
    "        accuracy_on_validation_set = ComputeAccuracy(X_validation, y_validation, W1, b1, W2, b2)\n",
    "        accuracies.append(accuracy_on_validation_set)\n",
    "        print('Accuracy performance on the validation set: ', accuracy_on_validation_set)\n",
    "        \n",
    "    sort_them_all = sorted(zip(accuracies, etas, lambdas))\n",
    "\n",
    "    best_accuracies = [x for x, _, _ in sort_them_all]\n",
    "    best_etas = [y for _, y, _ in sort_them_all]\n",
    "    best_lambdas = [z for _, _, z in sort_them_all]\n",
    "\n",
    "    print('---------------------------------')\n",
    "    print('BEST PERFORMANCE: ', str(best_accuracies[-1]))\n",
    "    print('Best eta: ', best_etas[-1])\n",
    "    print('Best lambda: ', best_lambdas[-1])\n",
    "    \n",
    "    print('---------------------------------')\n",
    "    print('SECOND BEST PERFORMANCE: ', str(best_accuracies[-2]))\n",
    "    print('Second best eta: ', best_etas[-2])\n",
    "    print('Second best lambda: ', best_lambdas[-2])\n",
    "    \n",
    "    print('---------------------------------')\n",
    "    print('THIRD BEST PERFORMANCE: ', str(best_accuracies[-3]))\n",
    "    print('Third best eta: ', best_etas[-3])\n",
    "    print('Third best lambda: ', best_lambdas[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run of fine search, with stable weight initialization of np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Learning rate: 0.018551777558089223, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  43.11\n",
      "---------------------------------\n",
      "Learning rate: 0.018394727031491028, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  43.91\n",
      "---------------------------------\n",
      "Learning rate: 0.018794276687985924, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  42.25\n",
      "---------------------------------\n",
      "Learning rate: 0.018241269856306787, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  41.24\n",
      "---------------------------------\n",
      "Learning rate: 0.018524400049430092, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  39.84\n",
      "---------------------------------\n",
      "Learning rate: 0.018965984141744892, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.28\n",
      "---------------------------------\n",
      "Learning rate: 0.01833161258277227, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.31\n",
      "---------------------------------\n",
      "Learning rate: 0.017482713735581825, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  39.51\n",
      "---------------------------------\n",
      "Learning rate: 0.017203967182204252, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  39.66\n",
      "---------------------------------\n",
      "Learning rate: 0.0177339958883317, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.9\n",
      "---------------------------------\n",
      "Learning rate: 0.027294804035699335, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  43.59\n",
      "---------------------------------\n",
      "Learning rate: 0.02768614807009409, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  42.73\n",
      "---------------------------------\n",
      "Learning rate: 0.027433248352692476, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  41.06\n",
      "---------------------------------\n",
      "Learning rate: 0.028291304100121397, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  39.71\n",
      "---------------------------------\n",
      "Learning rate: 0.0281266471986095, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.09\n",
      "---------------------------------\n",
      "Learning rate: 0.027381577145452658, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.18\n",
      "---------------------------------\n",
      "Learning rate: 0.02872811086425426, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.68\n",
      "---------------------------------\n",
      "Learning rate: 0.027145182713308166, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.25\n",
      "---------------------------------\n",
      "Learning rate: 0.027445041032857696, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.38\n",
      "---------------------------------\n",
      "Learning rate: 0.0277807530524516, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.48\n",
      "---------------------------------\n",
      "Learning rate: 0.024114800100445442, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  43.34\n",
      "---------------------------------\n",
      "Learning rate: 0.02440283052983749, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  42.62\n",
      "---------------------------------\n",
      "Learning rate: 0.02348139055456041, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  41.51\n",
      "---------------------------------\n",
      "Learning rate: 0.025620780601725342, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  40.28\n",
      "---------------------------------\n",
      "Learning rate: 0.025664861368040564, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.22\n",
      "---------------------------------\n",
      "Learning rate: 0.026037686941377255, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.58\n",
      "---------------------------------\n",
      "Learning rate: 0.02274944648471371, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.5\n",
      "---------------------------------\n",
      "Learning rate: 0.022884723661039094, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.07\n",
      "---------------------------------\n",
      "Learning rate: 0.02202774075754058, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.94\n",
      "---------------------------------\n",
      "Learning rate: 0.022819700438746923, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.43\n",
      "---------------------------------\n",
      "Learning rate: 0.026497140092720067, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.48\n",
      "---------------------------------\n",
      "Learning rate: 0.025354656912322908, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.69\n",
      "---------------------------------\n",
      "Learning rate: 0.026017548708873777, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.46\n",
      "---------------------------------\n",
      "Learning rate: 0.02286874976414767, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.13\n",
      "---------------------------------\n",
      "Learning rate: 0.02403351061617675, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.35\n",
      "---------------------------------\n",
      "Learning rate: 0.02384434332088455, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  37.67\n",
      "---------------------------------\n",
      "Learning rate: 0.023733628607507103, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  37.89\n",
      "---------------------------------\n",
      "Learning rate: 0.022559062001778266, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.48\n",
      "---------------------------------\n",
      "Learning rate: 0.024628749820408274, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.02\n",
      "---------------------------------\n",
      "Learning rate: 0.026362034980347383, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.99\n",
      "---------------------------------\n",
      "Learning rate: 0.017826300783925608, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.0\n",
      "---------------------------------\n",
      "Learning rate: 0.01713848118474131, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  44.44\n",
      "---------------------------------\n",
      "Learning rate: 0.017883358434445367, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.76\n",
      "---------------------------------\n",
      "Learning rate: 0.017902511492594277, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  40.66\n",
      "---------------------------------\n",
      "Learning rate: 0.018280745344583287, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  39.6\n",
      "---------------------------------\n",
      "Learning rate: 0.017444045108426447, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  38.53\n",
      "---------------------------------\n",
      "Learning rate: 0.018930170037312778, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  38.26\n",
      "---------------------------------\n",
      "Learning rate: 0.0172392255955838, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  37.44\n",
      "---------------------------------\n",
      "Learning rate: 0.017209158123335837, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  38.82\n",
      "---------------------------------\n",
      "Learning rate: 0.01768423975275892, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  38.72\n",
      "---------------------------------\n",
      "Learning rate: 0.029193158018971287, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.71\n",
      "---------------------------------\n",
      "Learning rate: 0.03122032892461537, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  42.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Learning rate: 0.03158470815148951, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  41.79\n",
      "---------------------------------\n",
      "Learning rate: 0.028971755173387584, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.61\n",
      "---------------------------------\n",
      "Learning rate: 0.029276101740644846, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.32\n",
      "---------------------------------\n",
      "Learning rate: 0.030082938532698444, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.35\n",
      "---------------------------------\n",
      "Learning rate: 0.029764805685603024, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.01\n",
      "---------------------------------\n",
      "Learning rate: 0.029477122315135385, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.67\n",
      "---------------------------------\n",
      "Learning rate: 0.030766947091804962, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.37\n",
      "---------------------------------\n",
      "Learning rate: 0.030384684033102898, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.41\n",
      "---------------------------------\n",
      "Learning rate: 0.030683234921777255, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.66\n",
      "---------------------------------\n",
      "Learning rate: 0.028582157678265174, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.11\n",
      "---------------------------------\n",
      "Learning rate: 0.03196654743302206, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.63\n",
      "---------------------------------\n",
      "Learning rate: 0.030109825809091724, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.55\n",
      "---------------------------------\n",
      "Learning rate: 0.029530150573103025, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.13\n",
      "---------------------------------\n",
      "Learning rate: 0.030993215070578305, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.31\n",
      "---------------------------------\n",
      "Learning rate: 0.0284060022195386, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  38.47\n",
      "---------------------------------\n",
      "Learning rate: 0.029533859510374412, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  37.76\n",
      "---------------------------------\n",
      "Learning rate: 0.028011698623292457, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  38.4\n",
      "---------------------------------\n",
      "Learning rate: 0.028884316476573718, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  38.04\n",
      "---------------------------------\n",
      "BEST PERFORMANCE:  44.44\n",
      "Best eta:  0.01713848118474131\n",
      "Best lambda:  0.0001\n",
      "---------------------------------\n",
      "SECOND BEST PERFORMANCE:  43.91\n",
      "Second best eta:  0.018394727031491028\n",
      "Second best lambda:  1e-06\n",
      "---------------------------------\n",
      "THIRD BEST PERFORMANCE:  43.71\n",
      "Third best eta:  0.029193158018971287\n",
      "Third best lambda:  0.001\n"
     ]
    }
   ],
   "source": [
    "fine_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second run of fine search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Learning rate: 0.017735018087604103, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  42.97\n",
      "---------------------------------\n",
      "Learning rate: 0.01746419667496226, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  43.42\n",
      "---------------------------------\n",
      "Learning rate: 0.018093247549295238, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  41.48\n",
      "---------------------------------\n",
      "Learning rate: 0.018926477020422043, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  40.29\n",
      "---------------------------------\n",
      "Learning rate: 0.018826625600027246, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.48\n",
      "---------------------------------\n",
      "Learning rate: 0.018152155213339433, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  39.51\n",
      "---------------------------------\n",
      "Learning rate: 0.018836422206563137, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.19\n",
      "---------------------------------\n",
      "Learning rate: 0.017318336044510982, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.65\n",
      "---------------------------------\n",
      "Learning rate: 0.01885412675376466, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.88\n",
      "---------------------------------\n",
      "Learning rate: 0.018946688167993896, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  39.03\n",
      "---------------------------------\n",
      "Learning rate: 0.028960908730851248, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  42.87\n",
      "---------------------------------\n",
      "Learning rate: 0.0287033408950022, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  41.32\n",
      "---------------------------------\n",
      "Learning rate: 0.02841414426365495, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  39.58\n",
      "---------------------------------\n",
      "Learning rate: 0.027022855138298597, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.95\n",
      "---------------------------------\n",
      "Learning rate: 0.028156600897847682, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.03\n",
      "---------------------------------\n",
      "Learning rate: 0.028437042628515177, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.55\n",
      "---------------------------------\n",
      "Learning rate: 0.028820806455506942, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.28\n",
      "---------------------------------\n",
      "Learning rate: 0.0284238099200546, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  38.53\n",
      "---------------------------------\n",
      "Learning rate: 0.027915506311373562, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.95\n",
      "---------------------------------\n",
      "Learning rate: 0.027003392358550114, amount of regularization term: 1e-06\n",
      "Accuracy performance on the validation set:  37.9\n",
      "---------------------------------\n",
      "Learning rate: 0.026925585997753746, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  43.73\n",
      "---------------------------------\n",
      "Learning rate: 0.023723641054404398, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  41.75\n",
      "---------------------------------\n",
      "Learning rate: 0.022483372485230017, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  40.07\n",
      "---------------------------------\n",
      "Learning rate: 0.025430739862279717, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.79\n",
      "---------------------------------\n",
      "Learning rate: 0.02671165395390538, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.22\n",
      "---------------------------------\n",
      "Learning rate: 0.025250034299789642, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.16\n",
      "---------------------------------\n",
      "Learning rate: 0.025909239708745313, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  37.67\n",
      "---------------------------------\n",
      "Learning rate: 0.024733656705384535, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  37.83\n",
      "---------------------------------\n",
      "Learning rate: 0.026431224756495963, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.25\n",
      "---------------------------------\n",
      "Learning rate: 0.02539972801275479, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  37.55\n",
      "---------------------------------\n",
      "Learning rate: 0.024573734109593313, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.25\n",
      "---------------------------------\n",
      "Learning rate: 0.022930380017020732, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.57\n",
      "---------------------------------\n",
      "Learning rate: 0.024770554882598137, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.44\n",
      "---------------------------------\n",
      "Learning rate: 0.023074642421019833, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.68\n",
      "---------------------------------\n",
      "Learning rate: 0.025248652008698212, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.69\n",
      "---------------------------------\n",
      "Learning rate: 0.026615902418217503, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.79\n",
      "---------------------------------\n",
      "Learning rate: 0.025389880259531226, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  38.72\n",
      "---------------------------------\n",
      "Learning rate: 0.024788775655680183, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  37.81\n",
      "---------------------------------\n",
      "Learning rate: 0.02256797035058726, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.55\n",
      "---------------------------------\n",
      "Learning rate: 0.02246710359818993, amount of regularization term: 1e-05\n",
      "Accuracy performance on the validation set:  39.74\n",
      "---------------------------------\n",
      "Learning rate: 0.01716377462060044, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.13\n",
      "---------------------------------\n",
      "Learning rate: 0.018920249916784752, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  44.16\n",
      "---------------------------------\n",
      "Learning rate: 0.018886526520259746, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.58\n",
      "---------------------------------\n",
      "Learning rate: 0.01895775207484601, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  41.09\n",
      "---------------------------------\n",
      "Learning rate: 0.017837232132587935, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  40.02\n",
      "---------------------------------\n",
      "Learning rate: 0.01860508913597894, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  39.29\n",
      "---------------------------------\n",
      "Learning rate: 0.01757275265658167, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  39.37\n",
      "---------------------------------\n",
      "Learning rate: 0.01867519552075304, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  39.14\n",
      "---------------------------------\n",
      "Learning rate: 0.01831889680782945, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  39.39\n",
      "---------------------------------\n",
      "Learning rate: 0.018383226218418123, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  38.43\n",
      "---------------------------------\n",
      "Learning rate: 0.02899354379782664, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  43.89\n",
      "---------------------------------\n",
      "Learning rate: 0.029894680133662425, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  42.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Learning rate: 0.030542572662875224, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  41.44\n",
      "---------------------------------\n",
      "Learning rate: 0.028178856969316702, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  41.38\n",
      "---------------------------------\n",
      "Learning rate: 0.031811813587325564, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.56\n",
      "---------------------------------\n",
      "Learning rate: 0.02832450608842571, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.64\n",
      "---------------------------------\n",
      "Learning rate: 0.02994829441224851, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  41.01\n",
      "---------------------------------\n",
      "Learning rate: 0.031428034046821915, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.92\n",
      "---------------------------------\n",
      "Learning rate: 0.03016526667860561, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.63\n",
      "---------------------------------\n",
      "Learning rate: 0.02975534714797813, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.13\n",
      "---------------------------------\n",
      "Learning rate: 0.030222389189687105, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.03\n",
      "---------------------------------\n",
      "Learning rate: 0.029584548896112912, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.42\n",
      "---------------------------------\n",
      "Learning rate: 0.029892750607658072, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.49\n",
      "---------------------------------\n",
      "Learning rate: 0.030664184519163303, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.88\n",
      "---------------------------------\n",
      "Learning rate: 0.030144105897441688, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  40.23\n",
      "---------------------------------\n",
      "Learning rate: 0.03041364832212037, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.95\n",
      "---------------------------------\n",
      "Learning rate: 0.030121784531941816, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.47\n",
      "---------------------------------\n",
      "Learning rate: 0.028291959918310614, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  38.0\n",
      "---------------------------------\n",
      "Learning rate: 0.03145057371016616, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  39.21\n",
      "---------------------------------\n",
      "Learning rate: 0.029114666820364458, amount of regularization term: 0.001\n",
      "Accuracy performance on the validation set:  38.4\n",
      "---------------------------------\n",
      "BEST PERFORMANCE:  44.16\n",
      "Best eta:  0.018920249916784752\n",
      "Best lambda:  0.0001\n",
      "---------------------------------\n",
      "SECOND BEST PERFORMANCE:  43.89\n",
      "Second best eta:  0.02899354379782664\n",
      "Second best lambda:  0.001\n",
      "---------------------------------\n",
      "THIRD BEST PERFORMANCE:  43.73\n",
      "Third best eta:  0.026925585997753746\n",
      "Third best lambda:  1e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([42.97,\n",
       "  43.42,\n",
       "  41.48,\n",
       "  40.29,\n",
       "  38.48,\n",
       "  39.51,\n",
       "  38.19,\n",
       "  37.65,\n",
       "  37.88,\n",
       "  39.03,\n",
       "  42.87,\n",
       "  41.32,\n",
       "  39.58,\n",
       "  38.95,\n",
       "  38.03,\n",
       "  38.55,\n",
       "  38.28,\n",
       "  38.53,\n",
       "  37.95,\n",
       "  37.9,\n",
       "  43.73,\n",
       "  41.75,\n",
       "  40.07,\n",
       "  39.79,\n",
       "  39.22,\n",
       "  39.16,\n",
       "  37.67,\n",
       "  37.83,\n",
       "  38.25,\n",
       "  37.55,\n",
       "  39.25,\n",
       "  39.57,\n",
       "  39.44,\n",
       "  39.68,\n",
       "  38.69,\n",
       "  38.79,\n",
       "  38.72,\n",
       "  37.81,\n",
       "  39.55,\n",
       "  39.74,\n",
       "  43.13,\n",
       "  44.16,\n",
       "  42.58,\n",
       "  41.09,\n",
       "  40.02,\n",
       "  39.29,\n",
       "  39.37,\n",
       "  39.14,\n",
       "  39.39,\n",
       "  38.43,\n",
       "  43.89,\n",
       "  42.48,\n",
       "  41.44,\n",
       "  41.38,\n",
       "  40.56,\n",
       "  40.64,\n",
       "  41.01,\n",
       "  39.92,\n",
       "  39.63,\n",
       "  40.13,\n",
       "  40.03,\n",
       "  40.42,\n",
       "  40.49,\n",
       "  39.88,\n",
       "  40.23,\n",
       "  39.95,\n",
       "  39.47,\n",
       "  38.0,\n",
       "  39.21,\n",
       "  38.4],\n",
       " [0.017735018087604103,\n",
       "  0.01746419667496226,\n",
       "  0.018093247549295238,\n",
       "  0.018926477020422043,\n",
       "  0.018826625600027246,\n",
       "  0.018152155213339433,\n",
       "  0.018836422206563137,\n",
       "  0.017318336044510982,\n",
       "  0.01885412675376466,\n",
       "  0.018946688167993896,\n",
       "  0.028960908730851248,\n",
       "  0.0287033408950022,\n",
       "  0.02841414426365495,\n",
       "  0.027022855138298597,\n",
       "  0.028156600897847682,\n",
       "  0.028437042628515177,\n",
       "  0.028820806455506942,\n",
       "  0.0284238099200546,\n",
       "  0.027915506311373562,\n",
       "  0.027003392358550114,\n",
       "  0.026925585997753746,\n",
       "  0.023723641054404398,\n",
       "  0.022483372485230017,\n",
       "  0.025430739862279717,\n",
       "  0.02671165395390538,\n",
       "  0.025250034299789642,\n",
       "  0.025909239708745313,\n",
       "  0.024733656705384535,\n",
       "  0.026431224756495963,\n",
       "  0.02539972801275479,\n",
       "  0.024573734109593313,\n",
       "  0.022930380017020732,\n",
       "  0.024770554882598137,\n",
       "  0.023074642421019833,\n",
       "  0.025248652008698212,\n",
       "  0.026615902418217503,\n",
       "  0.025389880259531226,\n",
       "  0.024788775655680183,\n",
       "  0.02256797035058726,\n",
       "  0.02246710359818993,\n",
       "  0.01716377462060044,\n",
       "  0.018920249916784752,\n",
       "  0.018886526520259746,\n",
       "  0.01895775207484601,\n",
       "  0.017837232132587935,\n",
       "  0.01860508913597894,\n",
       "  0.01757275265658167,\n",
       "  0.01867519552075304,\n",
       "  0.01831889680782945,\n",
       "  0.018383226218418123,\n",
       "  0.02899354379782664,\n",
       "  0.029894680133662425,\n",
       "  0.030542572662875224,\n",
       "  0.028178856969316702,\n",
       "  0.031811813587325564,\n",
       "  0.02832450608842571,\n",
       "  0.02994829441224851,\n",
       "  0.031428034046821915,\n",
       "  0.03016526667860561,\n",
       "  0.02975534714797813,\n",
       "  0.030222389189687105,\n",
       "  0.029584548896112912,\n",
       "  0.029892750607658072,\n",
       "  0.030664184519163303,\n",
       "  0.030144105897441688,\n",
       "  0.03041364832212037,\n",
       "  0.030121784531941816,\n",
       "  0.028291959918310614,\n",
       "  0.03145057371016616,\n",
       "  0.029114666820364458],\n",
       " [1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  1e-05,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_search(e_min=np.log(0.017), e_max=np.log(0.019)):\n",
    "    \"\"\"\n",
    "    Final search, optimal value for the learning rate may be found between 0.017 and 0.019\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    training_data, validation_data, test_data, W1, b1, W2, b2 = exercise_1()\n",
    "    X_training, Y_training, y_training = training_data\n",
    "    X_validation, Y_validation, y_validation = validation_data\n",
    "\n",
    "    accuracies = []\n",
    "    etas = []\n",
    "    lambdas = []\n",
    "\n",
    "    regularization_term = 0.0001\n",
    "\n",
    "    for _ in range(40):\n",
    "        np.random.seed()\n",
    "        eta_term = np.random.rand(1, 1).flatten()[0]\n",
    "        e = e_min + (e_max - e_min) * eta_term\n",
    "        eta = np.exp(e)\n",
    "        etas.append(eta)\n",
    "\n",
    "        lambdas.append(regularization_term)\n",
    "\n",
    "        GD_params = [100, eta, 10]\n",
    "\n",
    "        W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                         Y_training,\n",
    "                                                                                         X_validation,\n",
    "                                                                                         Y_validation,\n",
    "                                                                                         y_validation,\n",
    "                                                                                         GD_params,\n",
    "                                                                                         W1, b1, W2, b2,\n",
    "                                                                                         regularization_term=regularization_term)\n",
    "        print('---------------------------------')\n",
    "        print('Learning rate: ' + str(eta) + ', amount of regularization term: ' + str(regularization_term))\n",
    "        accuracy_on_validation_set = ComputeAccuracy(X_validation, y_validation, W1, b1, W2, b2)\n",
    "        accuracies.append(accuracy_on_validation_set)\n",
    "        print('Accuracy performance on the validation set: ', accuracy_on_validation_set)\n",
    "\n",
    "        W1, b1, W2, b2 = initialize_weights(d=X_training.shape[0], m=50, K=Y_training.shape[0])\n",
    "\n",
    "    sort_them_all = sorted(zip(accuracies, etas, lambdas))\n",
    "\n",
    "    best_accuracies = [x for x, _, _ in sort_them_all]\n",
    "    best_etas = [y for _, y, _ in sort_them_all]\n",
    "    best_lambdas = [z for _, _, z in sort_them_all]\n",
    "\n",
    "    print('---------------------------------')\n",
    "    print('BEST PERFORMANCE: ', str(best_accuracies[-1]))\n",
    "    print('Best eta: ', best_etas[-1])\n",
    "    print('Best lambda: ', best_lambdas[-1])\n",
    "\n",
    "    print('---------------------------------')\n",
    "    print('SECOND BEST PERFORMANCE: ', str(best_accuracies[-2]))\n",
    "    print('Second best eta: ', best_etas[-2])\n",
    "    print('Second best lambda: ', best_lambdas[-2])\n",
    "\n",
    "    print('---------------------------------')\n",
    "    print('THIRD BEST PERFORMANCE: ', str(best_accuracies[-3]))\n",
    "    print('Third best eta: ', best_etas[-3])\n",
    "    print('Third best lambda: ', best_lambdas[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Learning rate: 0.01807778788365891, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  44.03\n",
      "---------------------------------\n",
      "Learning rate: 0.01841866665259337, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.92\n",
      "---------------------------------\n",
      "Learning rate: 0.018870547435632684, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.22\n",
      "---------------------------------\n",
      "Learning rate: 0.01739688358362078, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.21\n",
      "---------------------------------\n",
      "Learning rate: 0.018349819029981264, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.66\n",
      "---------------------------------\n",
      "Learning rate: 0.018614612584802317, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.15\n",
      "---------------------------------\n",
      "Learning rate: 0.01724050332547346, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.22\n",
      "---------------------------------\n",
      "Learning rate: 0.018096296777051015, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.03\n",
      "---------------------------------\n",
      "Learning rate: 0.018506292261733805, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.71\n",
      "---------------------------------\n",
      "Learning rate: 0.018069856639751438, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.84\n",
      "---------------------------------\n",
      "Learning rate: 0.017528068652450317, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.13\n",
      "---------------------------------\n",
      "Learning rate: 0.018382327875119828, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.46\n",
      "---------------------------------\n",
      "Learning rate: 0.017178390309476373, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.87\n",
      "---------------------------------\n",
      "Learning rate: 0.0188081986995635, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.32\n",
      "---------------------------------\n",
      "Learning rate: 0.0186842974927458, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.32\n",
      "---------------------------------\n",
      "Learning rate: 0.017931487454850372, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.44\n",
      "---------------------------------\n",
      "Learning rate: 0.017090664204536074, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.3\n",
      "---------------------------------\n",
      "Learning rate: 0.017527890860166075, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.14\n",
      "---------------------------------\n",
      "Learning rate: 0.018136037068560328, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.28\n",
      "---------------------------------\n",
      "Learning rate: 0.017359174886368105, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.07\n",
      "---------------------------------\n",
      "Learning rate: 0.01868040156643904, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.8\n",
      "---------------------------------\n",
      "Learning rate: 0.017924589704608283, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.34\n",
      "---------------------------------\n",
      "Learning rate: 0.01729656405769053, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.89\n",
      "---------------------------------\n",
      "Learning rate: 0.017970168260122585, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.13\n",
      "---------------------------------\n",
      "Learning rate: 0.018274796360141378, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.68\n",
      "---------------------------------\n",
      "Learning rate: 0.0188145540272405, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.94\n",
      "---------------------------------\n",
      "Learning rate: 0.01835280264149484, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.42\n",
      "---------------------------------\n",
      "Learning rate: 0.0173489262822629, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.22\n",
      "---------------------------------\n",
      "Learning rate: 0.018803676443936775, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.34\n",
      "---------------------------------\n",
      "Learning rate: 0.018258020215840633, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.08\n",
      "---------------------------------\n",
      "Learning rate: 0.017424093121188956, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.57\n",
      "---------------------------------\n",
      "Learning rate: 0.018664555107327566, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.23\n",
      "---------------------------------\n",
      "Learning rate: 0.017135783700420595, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.28\n",
      "---------------------------------\n",
      "Learning rate: 0.018114031048503353, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.29\n",
      "---------------------------------\n",
      "Learning rate: 0.017277801340627133, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.95\n",
      "---------------------------------\n",
      "Learning rate: 0.01717609273357587, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.17\n",
      "---------------------------------\n",
      "Learning rate: 0.01782213452408423, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.02\n",
      "---------------------------------\n",
      "Learning rate: 0.01704397022841666, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  42.81\n",
      "---------------------------------\n",
      "Learning rate: 0.01724735703689069, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.24\n",
      "---------------------------------\n",
      "Learning rate: 0.018616815969639464, amount of regularization term: 0.0001\n",
      "Accuracy performance on the validation set:  43.33\n",
      "---------------------------------\n",
      "BEST PERFORMANCE:  44.03\n",
      "Best eta:  0.01807778788365891\n",
      "Best lambda:  0.0001\n",
      "---------------------------------\n",
      "SECOND BEST PERFORMANCE:  43.94\n",
      "Second best eta:  0.0188145540272405\n",
      "Second best lambda:  0.0001\n",
      "---------------------------------\n",
      "THIRD BEST PERFORMANCE:  43.71\n",
      "Third best eta:  0.018506292261733805\n",
      "Third best lambda:  0.0001\n"
     ]
    }
   ],
   "source": [
    "final_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For your best found hyperparameter settings, train the network on all the training data (all the batch data), except for 1000 examples in a validation set, for ∼30 epochs. Plot the training and validation cost after each epoch of training and then report the learnt network’s performance on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sets():\n",
    "\n",
    "    X_training_1, Y_training_1, y_training_1 = LoadBatch('../../cifar-10-batches-py/data_batch_1')\n",
    "    X_training_2, Y_training_2, y_training_2 = LoadBatch('../../cifar-10-batches-py/data_batch_2')\n",
    "    X_training_3, Y_training_3, y_training_3 = LoadBatch('../../cifar-10-batches-py/data_batch_3')\n",
    "    X_training_4, Y_training_4, y_training_4 = LoadBatch('../../cifar-10-batches-py/data_batch_4')\n",
    "    X_training_5, Y_training_5, y_training_5 = LoadBatch('../../cifar-10-batches-py/data_batch_5')\n",
    "\n",
    "    X_training = np.concatenate((X_training_1, X_training_3), axis=1)\n",
    "    X_training = np.copy(np.concatenate((X_training, X_training_4), axis=1))\n",
    "    X_training = np.copy(np.concatenate((X_training, X_training_5), axis=1))\n",
    "\n",
    "    X_training = np.concatenate((X_training, X_training_2[:, :9000]), axis=1)\n",
    "\n",
    "    Y_training = np.concatenate((Y_training_1, Y_training_3), axis=1)\n",
    "    Y_training = np.copy(np.concatenate((Y_training, Y_training_4), axis=1))\n",
    "    Y_training = np.copy(np.concatenate((Y_training, Y_training_5), axis=1))\n",
    "\n",
    "    Y_training = np.concatenate((Y_training, Y_training_2[:, :9000]), axis=1)\n",
    "\n",
    "    y_training = y_training_1 + y_training_3 + y_training_4 + y_training_5 + y_training_2[:9000]\n",
    "\n",
    "    X_validation = np.copy(X_training_2[:, 9000:])\n",
    "    Y_validation = np.copy(Y_training_2[:, 9000:])\n",
    "    y_validation = y_training_2[9000:]\n",
    "\n",
    "    X_test, _, y_test = LoadBatch('../../cifar-10-batches-py/test_batch')\n",
    "\n",
    "    mean = np.mean(X_training)\n",
    "    X_training -= mean\n",
    "    X_validation -= mean\n",
    "    X_test -= mean\n",
    "\n",
    "    return [X_training, Y_training, y_training], [X_validation, Y_validation, y_validation], [X_test, y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, test = create_sets()\n",
    "\n",
    "X_training, Y_training, y_training = training\n",
    "X_validation, Y_validation, y_validation = validation\n",
    "X_test, y_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment no.1: Eta = 0.018920249916784752, lambda = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = initialize_weights()\n",
    "\n",
    "GD_params = [100, 0.018920249916784752, 30]\n",
    "\n",
    "W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                 Y_training,\n",
    "                                                                                 X_validation,\n",
    "                                                                                 Y_validation,\n",
    "                                                                                 y_validation,\n",
    "                                                                                 GD_params,\n",
    "                                                                                 W1, b1, W2, b2,\n",
    "                                                                                 regularization_term=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_costs(training_set_loss,validation_set_loss, display=True, title='Cross Entropy Loss Evolution, $\\eta=0.018920249916784752$', save_name='experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_accuracy_1 = ComputeAccuracy(X_test, y_test, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved on the test set was $50.23\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.23"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_accuracy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment no.2: Eta = 0.01713848118474131, lambda = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD_params = [100, 0.01713848118474131, 30]\n",
    "\n",
    "W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                 Y_training,\n",
    "                                                                                 X_validation,\n",
    "                                                                                 Y_validation,\n",
    "                                                                                 y_validation,\n",
    "                                                                                 GD_params,\n",
    "                                                                                 W1, b1, W2, b2,\n",
    "                                                                                 regularization_term=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_costs(training_set_loss,validation_set_loss, display=True, title='Cross Entropy Loss Evolution, $\\eta=0.01713848118474131$', save_name='experiment_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_accuracy_2 = ComputeAccuracy(X_test, y_test, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved on the test set was $49.14\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.14"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_accuracy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment no.3: Eta = 0.02878809988519304, lambda = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [39:19<00:00, 78.65s/it]\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = initialize_weights()\n",
    "\n",
    "GD_params = [100, 0.02878809988519304, 30]\n",
    "\n",
    "W1, b1, W2, b2, training_set_loss, validation_set_loss = MiniBatchGDwithMomentum(X_training,\n",
    "                                                                                 Y_training,\n",
    "                                                                                 X_validation,\n",
    "                                                                                 Y_validation,\n",
    "                                                                                 y_validation,\n",
    "                                                                                 GD_params,\n",
    "                                                                                 W1, b1, W2, b2,\n",
    "                                                                                 regularization_term=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_costs(training_set_loss,validation_set_loss, display=True, title='Cross Entropy Loss Evolution, $\\eta=0.02878809988519304', save_name='experiment_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_accuracy_3 = ComputeAccuracy(X_test, y_test, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved on the test set was $51.04\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.04"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_accuracy_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
